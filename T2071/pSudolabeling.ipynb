{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import PIL\n",
    "import os\n",
    "from glob import glob\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import timm\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from adamp import AdamP\n",
    "from tqdm import tqdm, notebook\n",
    "from PIL import Image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "train_dir = '/opt/ml/input/data/train/new_imgs'\n",
    "transform = T.Compose([\n",
    "    T.Resize((224,224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246))\n",
    "]) \n",
    "\n",
    "seed = 37\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(f'seed : {seed}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "seed : 37\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class maskImageDataset(Dataset):\n",
    "    def __init__(self,path,transform=None):\n",
    "        self.image,self.label = self.labeling(path)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        image,label = Image.open(self.image[idx]),self.label[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image,label\n",
    "\n",
    "    def __len__(self):\n",
    "            return len(self.label)\n",
    "\n",
    "    def labeling(self,paths):\n",
    "        x = []\n",
    "        y = []\n",
    "        for dic in os.listdir(paths):\n",
    "            if '._' in dic or 'ipynb_checkpoints' in dic:\n",
    "                continue\n",
    "            dir_path = paths + '/'+ dic\n",
    "            code = 0\n",
    "            if dic[7] == 'f':\n",
    "                code = 3\n",
    "            age = int(dic[-2:])\n",
    "            if age >= 60:\n",
    "                code += 2\n",
    "            elif age >=30:\n",
    "                code += 1\n",
    "            for image in os.listdir(dir_path):\n",
    "                if '._' in image or 'ipynb_checkpoints' in image:\n",
    "                    continue\n",
    "                if 'png' in image:\n",
    "                    continue\n",
    "                image_path = dir_path + '/' + image \n",
    "                x.append(image_path)\n",
    "                label = [0 for _ in range(18)]\n",
    "                y.append(self.age_labeling(image,code))\n",
    "        return x,y\n",
    "                \n",
    "    def age_labeling(self,path,inputs):\n",
    "        if 'incorrect_mask' in path:\n",
    "            return inputs + 6\n",
    "        elif 'normal' in path:\n",
    "            return inputs + 12\n",
    "        else:\n",
    "            return inputs\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "DATA = maskImageDataset(train_dir,transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=DATA, batch_size=16,shuffle=True)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def create_model(num_classes):\n",
    "    model = timm.create_model('tf_efficientnet_b5', pretrained=True, num_classes = num_classes)\n",
    "    model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Linear(2048, num_classes)\n",
    "    )\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(f\"{device} is using!\")\n",
    "efficientnet_b5=create_model(18)\n",
    "efficientnet_b5.to(device)\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCH = 5 \n",
    "loss_fn = torch.nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(efficientnet_b5.parameters(), lr=LEARNING_RATE)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda:0 is using!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from tqdm.notebook import tqdm\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "dataloaders = {\n",
    "    \"train\" : train_loader,\n",
    "\n",
    "}\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "best_test_accuracy=0\n",
    "best_test_loss=9999.\n",
    "for epoch in range(5):\n",
    "    for phase in [\"train\"]:\n",
    "        running_loss=0.\n",
    "        running_acc=0.\n",
    "        if phase == \"train\":\n",
    "            efficientnet_b5.train()\n",
    "        if phase == \"val\":\n",
    "            efficientnet_b5.eval()\n",
    "        \n",
    "        for ind, (images, labels) in enumerate(tqdm(dataloaders[phase])):\n",
    "            images=images.to(device)\n",
    "            labels=labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.set_grad_enabled(phase==\"train\"):\n",
    "                logits=efficientnet_b5(images)\n",
    "                _,preds=torch.max(logits,1)\n",
    "                loss=loss_fn(logits,labels)\n",
    "            if phase ==\"train\":\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "            running_loss+=loss.item()*images.size(0)\n",
    "            running_acc+=torch.sum(preds==labels.data)\n",
    "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "        epoch_acc = running_acc / len(dataloaders[phase].dataset)\n",
    "    print(f\"현재 epoch-{epoch}의 {phase}-데이터 셋에서 평균 Loss : {epoch_loss:.3f}, 평균 Accuracy : {epoch_acc:.3f}\")\n",
    "    if phase == \"test\" and best_test_accuracy < epoch_acc: \n",
    "      best_test_accuracy = epoch_acc\n",
    "    if phase == \"test\" and best_test_loss > epoch_loss:\n",
    "      best_test_loss = epoch_loss\n",
    "print(\"학습 종료!\")\n",
    "print(f\"최고 accuracy : {best_test_accuracy}, 최고 낮은 loss : {best_test_loss}\")\n",
    "PATH = './'\n",
    "torch.save(efficientnet_b5,'./efficientnet_b5.pt')\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1150.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f86e291af1894ab0beebb0c75ca0b5b8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "현재 epoch-0의 train-데이터 셋에서 평균 Loss : 0.556, 평균 Accuracy : 0.835\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1150.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "187f893345f846be820e2c36cd604118"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "현재 epoch-1의 train-데이터 셋에서 평균 Loss : 0.130, 평균 Accuracy : 0.961\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1150.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7bfefabc048142d78fc4ddfd384ab8f8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "현재 epoch-2의 train-데이터 셋에서 평균 Loss : 0.058, 평균 Accuracy : 0.982\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1150.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8bbef154706f4c7f9c62608ced55ef2f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "현재 epoch-3의 train-데이터 셋에서 평균 Loss : 0.038, 평균 Accuracy : 0.988\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1150.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac27e765b1854961ae5ccc6609d97f3e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "현재 epoch-4의 train-데이터 셋에서 평균 Loss : 0.038, 평균 Accuracy : 0.988\n",
      "학습 종료!\n",
      "최고 accuracy : 0, 최고 낮은 loss : 9999.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "test_dir = '/opt/ml/input/data/eval'\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = './new_images'\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224) ),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246))\n",
    "])\n",
    "dataset = TestDataset(image_paths, transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "efficientnet_b5 = torch.load('./Seudo_efficientnet_b5.pt')\n",
    "efficientnet_b5.eval()\n",
    "SoftMax=nn.Softmax()\n",
    "threshold=0.7\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = efficientnet_b5(images)\n",
    "        probs = SoftMax(pred)\n",
    "        if torch.max(probs)>=threshold:\n",
    "            pred = pred.argmax(dim=-1)\n",
    "            all_predictions.extend(pred.cpu().numpy())\n",
    "            continue\n",
    "        all_predictions.extend(torch.Tensor([100]))\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv( './Sudo_efficientnet_b5.csv', index=False)\n",
    "print('test inference is done!')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-86-7e99797ff32c>:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = SoftMax(pred)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "temp1=pd.read_csv('./efficientnet_b5.csv')\n",
    "temp1['ans'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0               2283\n",
       "1               2001\n",
       "3               1499\n",
       "4               1467\n",
       "tensor(100.)     769\n",
       "2                685\n",
       "13               547\n",
       "7                534\n",
       "6                459\n",
       "12               452\n",
       "5                390\n",
       "10               358\n",
       "15               314\n",
       "9                298\n",
       "16               286\n",
       "8                 97\n",
       "17                61\n",
       "11                55\n",
       "14                45\n",
       "Name: ans, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "temp2=pd.read_csv('./Sudo_efficientnet_b5.csv')\n",
    "temp2['ans'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0               2329\n",
       "1               2187\n",
       "4               1579\n",
       "3               1510\n",
       "2                800\n",
       "13               561\n",
       "7                521\n",
       "12               468\n",
       "6                459\n",
       "5                388\n",
       "10               373\n",
       "15               315\n",
       "9                301\n",
       "16               298\n",
       "tensor(100.)     182\n",
       "8                111\n",
       "17                78\n",
       "11                75\n",
       "14                65\n",
       "Name: ans, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "temp3=pd.read_csv('./tmp.csv')\n",
    "\n",
    "len(temp3)\n",
    "len(temp2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "12600"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "cnt=0\n",
    "for i in range(int(len(temp2))):\n",
    "    if '(' in temp2['ans'][i]:\n",
    "        continue\n",
    "    if int(temp3['ans'][i]) == int(temp2['ans'][i]):\n",
    "       cnt+=1\n",
    "print(cnt)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10273\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "temp4=pd.read_csv('./efficientnet_b5.csv')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "cnt=0\n",
    "for i in range(int(len(temp4))):\n",
    "    if '(' in temp4['ans'][i]:\n",
    "        continue\n",
    "    if int(temp3['ans'][i]) == int(temp4['ans'][i]):\n",
    "       cnt+=1\n",
    "print(cnt)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9950\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "pseudo_csv_path='./efficientnet_b5.csv'\n",
    "pseudo_image='./new_images'\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224) ),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246))\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "class SeudoDataset(Dataset):\n",
    "    def __init__(self,csv_path,img_path,transform=None):\n",
    "        self.image,self.label = self.labeling(csv_path,img_path)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        image,label = Image.open(self.image[idx]),self.label[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image,label\n",
    "\n",
    "    def __len__(self):\n",
    "            return len(self.label)\n",
    "\n",
    "    def labeling(self,csv_path,img_path):\n",
    "        x = []\n",
    "        y = []\n",
    "        seudo_csv=pd.read_csv(csv_path)\n",
    "        for i in range(len(seudo_csv)):\n",
    "            if ')' in seudo_csv['ans'][i]:\n",
    "                continue\n",
    "            x.append(os.path.join(img_path,seudo_csv['ImageID'][i]))\n",
    "            temp=int(seudo_csv['ans'][i])\n",
    "            y.append(torch.tensor(temp))\n",
    "        return x,y\n",
    "                \n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "Seudo_Data=SeudoDataset(pseudo_csv_path,pseudo_image,transform)\n",
    "Seudo_Data[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[-1.1705, -1.5180, -1.3194,  ..., -1.6669, -1.4684, -1.2036],\n",
       "          [-1.4684, -1.3691, -1.1871,  ..., -1.4849, -1.0712, -0.7072],\n",
       "          [-1.4518, -0.9885, -0.7403,  ..., -0.9885, -0.5583, -0.3928],\n",
       "          ...,\n",
       "          [-1.5014, -1.4353, -1.4187,  ..., -1.4353, -1.5014, -1.5676],\n",
       "          [-1.5345, -1.4684, -1.3360,  ..., -1.4022, -1.4684, -1.5345],\n",
       "          [-1.4022, -1.3360, -1.2698,  ..., -1.4187, -1.4849, -1.5511]],\n",
       " \n",
       "         [[-0.9132, -1.2466, -1.0561,  ..., -1.4689, -1.2625, -1.0244],\n",
       "          [-1.1990, -1.1038, -0.9291,  ..., -1.2784, -0.8815, -0.5481],\n",
       "          [-1.1831, -0.7386, -0.5004,  ..., -0.8180, -0.3893, -0.2623],\n",
       "          ...,\n",
       "          [-1.1990, -1.1355, -1.1196,  ..., -1.1514, -1.2149, -1.2784],\n",
       "          [-1.2308, -1.1673, -1.0402,  ..., -1.1196, -1.1831, -1.2466],\n",
       "          [-1.1038, -1.0402, -0.9767,  ..., -1.1355, -1.1990, -1.2625]],\n",
       " \n",
       "         [[-0.8631, -1.1979, -1.0066,  ..., -1.5486, -1.3573, -1.1660],\n",
       "          [-1.1501, -1.0544, -0.8791,  ..., -1.3573, -0.9747, -0.6878],\n",
       "          [-1.1341, -0.6878, -0.4487,  ..., -0.8472, -0.4646, -0.3530],\n",
       "          ...,\n",
       "          [-0.6718, -0.6081, -0.5921,  ..., -0.7834, -0.8472, -0.9110],\n",
       "          [-0.7037, -0.6400, -0.5124,  ..., -0.7516, -0.8153, -0.8791],\n",
       "          [-0.5762, -0.5124, -0.4487,  ..., -0.7675, -0.8313, -0.8950]]]),\n",
       " tensor(13))"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "Seudo_Loader = DataLoader(dataset=Seudo_Data, batch_size=16,shuffle=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "\n",
    "seudo_model=torch.load('./efficientnet_b5.pt')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "seudo_model.to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss() \n",
    "LEARNING_RATE = 0.0001\n",
    "optimizer = torch.optim.Adam(seudo_model.parameters(), lr=LEARNING_RATE)\n",
    "dataloaders = {\n",
    "    \"train\" : Seudo_Loader,\n",
    "}\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "best_test_accuracy=0\n",
    "best_test_loss=9999.\n",
    "for epoch in range(5):\n",
    "    for phase in [\"train\"]:\n",
    "        running_loss=0.\n",
    "        running_acc=0.\n",
    "        if phase == \"train\":\n",
    "            seudo_model.train()\n",
    "        if phase == \"val\":\n",
    "            seudo_model.eval()\n",
    "        \n",
    "        for ind, (images, labels) in enumerate(tqdm(dataloaders[phase])):\n",
    "            images=images.to(device)\n",
    "            labels=labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.set_grad_enabled(phase==\"train\"):\n",
    "                logits=seudo_model(images)\n",
    "                _,preds=torch.max(logits,1)\n",
    "                loss=loss_fn(logits,labels)\n",
    "            if phase ==\"train\":\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "            running_loss+=loss.item()*images.size(0)\n",
    "            running_acc+=torch.sum(preds==labels.data)\n",
    "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "        epoch_acc = running_acc / len(dataloaders[phase].dataset)\n",
    "    print(f\"현재 epoch-{epoch}의 {phase}-데이터 셋에서 평균 Loss : {epoch_loss:.3f}, 평균 Accuracy : {epoch_acc:.3f}\")\n",
    "    if phase == \"test\" and best_test_accuracy < epoch_acc: \n",
    "      best_test_accuracy = epoch_acc\n",
    "    if phase == \"test\" and best_test_loss > epoch_loss:\n",
    "      best_test_loss = epoch_loss\n",
    "print(\"학습 종료!\")\n",
    "print(f\"최고 accuracy : {best_test_accuracy}, 최고 낮은 loss : {best_test_loss}\")\n",
    "\n",
    "torch.save(seudo_model,'./Seudo_efficientnet_b5.pt')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 740/740 [03:05<00:00,  3.98it/s]\n",
      "  0%|          | 0/740 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "현재 epoch-0의 train-데이터 셋에서 평균 Loss : 0.180, 평균 Accuracy : 0.940\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 740/740 [03:05<00:00,  3.99it/s]\n",
      "  0%|          | 0/740 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "현재 epoch-1의 train-데이터 셋에서 평균 Loss : 0.080, 평균 Accuracy : 0.975\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 740/740 [03:07<00:00,  3.95it/s]\n",
      "  0%|          | 0/740 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "현재 epoch-2의 train-데이터 셋에서 평균 Loss : 0.056, 평균 Accuracy : 0.981\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 740/740 [03:04<00:00,  4.02it/s]\n",
      "  0%|          | 0/740 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "현재 epoch-3의 train-데이터 셋에서 평균 Loss : 0.030, 평균 Accuracy : 0.990\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 740/740 [02:59<00:00,  4.12it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "현재 epoch-4의 train-데이터 셋에서 평균 Loss : 0.040, 평균 Accuracy : 0.987\n",
      "학습 종료!\n",
      "최고 accuracy : 0, 최고 낮은 loss : 9999.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}