{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# data manipulation\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "import random\n",
                "import os\n",
                "\n",
                "import torch\n",
                "import torchvision\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "\n",
                "from torch.utils.data import DataLoader\n",
                "from tqdm.notebook import tqdm\n",
                "\n",
                "from maskdataset import MaskDataset\n",
                "from labeling import MakeLabel\n",
                "\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "path = {\"train_label\" : '/opt/ml/input/data/train/train_with_labels_fix_wrong_data.csv',\n",
                "        \"train_vanilla\" : '/opt/ml/input/data/train/train.csv'}\n",
                "\n",
                "wrong_data = {\"gender\" :  ['006359', '006360', '006361', '006362', '006363', '006364', '001498-1', '004432'],\n",
                "              \"mask\" : (['000020', '004418', '005227'], 'incollect_mask', 'normal')}\n",
                "\n",
                "train_label_fixed = MakeLabel(path=path, wrong_data=wrong_data)\n",
                "train_label_fixed.labeling()\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Set random seed\n",
                "SEED = 2021\n",
                "random.seed(SEED)\n",
                "np.random.seed(SEED)\n",
                "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
                "torch.manual_seed(SEED)\n",
                "torch.cuda.manual_seed(SEED)  # type: ignore\n",
                "torch.backends.cudnn.deterministic = True  # type: ignore\n",
                "torch.backends.cudnn.benchmark = True  # type: ignore"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "model=torchvision.models.resnet18(pretrained=True)\n",
                "\n",
                "for param in model.parameters():\n",
                "    param.requires_grad=False\n",
                "\n",
                "print(\"네트워크 입력 채널 개수: \",model.conv1.weight.shape[1])\n",
                "print(\"네트워크 입력 차원 개수: \",model.fc.weight.shape[0])\n",
                "print(''.join([\"*\"*15,\"변경중\",\"*\"*30]))\n",
                "\n",
                "import math\n",
                "import torch.nn as nn\n",
                "# model.fc = torch.nn.Linear(in_features=model.fc.in_features, out_features=18, bias=True)\n",
                "# model.fc = torch.nn.Sequential(\n",
                "#     nn.Linear(in_features=model.fc.in_features, out_features=18, bias=True)\n",
                "# )\n",
                "model.fc = nn.Sequential(\n",
                "                      nn.Linear(model.fc.in_features, 256), \n",
                "                      nn.ReLU(), \n",
                "                      nn.Dropout(0.4),\n",
                "                      nn.Linear(256, 18))\n",
                "torch.nn.init.xavier_uniform_(model.fc[0].weight)\n",
                "\n",
                "stdv = 1. / math.sqrt(model.fc[0].weight.size(1))\n",
                "model.fc[0].bias.data.uniform_(-stdv, stdv)\n",
                "\n",
                "torch.nn.init.xavier_uniform_(model.fc[3].weight)\n",
                "stdv = 1. / math.sqrt(model.fc[3].weight.size(1))\n",
                "model.fc[3].bias.data.uniform_(-stdv, stdv)\n",
                "\n",
                "\n",
                "\n",
                "print(\"네트워크 입력 채널 개수\", model.conv1.weight.shape[1])\n",
                "print(\"네트워크 출력 차원 개수\", model.fc[3].weight.shape[0])\n",
                "\n",
                "# model"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "from maskdataset import MaskDataset\n",
                "from torchvision import transforms\n",
                "from PIL import Image\n",
                "transform=transforms.Compose([\n",
                "            # transforms.Resize((300,384), Image.BILINEAR),\n",
                "            transforms.ToTensor(),\n",
                "            # transforms.CenterCrop((200,200)),\n",
                "            # transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))\n",
                "            transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.2,0.2,0.2))\n",
                "            ])\n",
                "\n",
                "train_dataset = MaskDataset(transform=transform,train=True)\n",
                "\n",
                "\n",
                "batch_size =25\n",
                "dataloader_train = DataLoader(dataset=train_dataset,\n",
                "                              batch_size=batch_size,\n",
                "                              shuffle=True,\n",
                "                              drop_last=True)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
                "\n",
                "model.to(device) #regnet을 GPU에 load\n",
                "\n",
                "from collections import Counter\n",
                "class_weights = [v for _, v in sorted(Counter(train_dataset.y).items())]\n",
                "class_weights = list(map(lambda x : max(class_weights)/x,class_weights))\n",
                "class_weights = torch.FloatTensor(class_weights).to(device)\n",
                "print(class_weights)\n",
                "lr = 0.0001\n",
                "num_epoch = 5\n",
                "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import warnings\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "from sklearn.metrics import f1_score\n",
                "\n",
                "### 학습 시작\n",
                "best_test_f1_score = 0\n",
                "best_test_loss = 9999\n",
                "model.train()\n",
                "\n",
                "for epoch in range(num_epoch):\n",
                "    tmp_loss = 0\n",
                "    tmp_f1score = 0\n",
                "    tmp_acc = 0\n",
                "\n",
                "    for idx, (images,labels) in enumerate(tqdm(dataloader_train)):\n",
                "        images = images.to(device)\n",
                "        labels = labels.to(device)\n",
                "\n",
                "        optimizer.zero_grad()\n",
                "        logits = model(images)\n",
                "        _, preds = torch.max(logits,dim=-1)\n",
                "        loss = loss_fn(logits,labels)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        f1score = f1_score(labels.cpu(),preds.cpu(),average=\"macro\")\n",
                "        tmp_acc += sum(labels.cpu()==preds.cpu())\n",
                "        tmp_loss += loss.item() * images.size(0)\n",
                "        tmp_f1score += f1score # 각 batch별로 f1 score 계산\n",
                "\n",
                "    epoch_acc = tmp_acc / len(dataloader_train.dataset)\n",
                "    epoch_f1score = tmp_f1score/(idx+1) \n",
                "    epoch_loss = tmp_loss / len(dataloader_train.dataset)\n",
                "    print(f\"현재 epoch-{epoch+1} -데이터 셋에서 평균 Loss : {epoch_loss:.5f}, 평균 f1-score : {epoch_f1score:.3f}, 평균 acc : {epoch_acc:.3f}\")\n",
                "    if best_test_f1_score < epoch_f1score:\n",
                "        best_test_f1_score = epoch_f1score\n",
                "        best_test_loss = epoch_loss\n",
                "        best_test_acc = epoch_acc\n",
                "        print(\"best f1 score updated\")\n",
                "print(\"학습 종료!\")\n",
                "print(f\"최고 f1_score : {best_test_f1_score} 일 떄 loss : {best_test_loss}, acc : {best_test_acc}\")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "from maskdataset import MaskDataset\n",
                "validation_dataset = MaskDataset(transform=transform, train=False)\n",
                "dataloader_validation = DataLoader(dataset=validation_dataset,\n",
                "                                   shuffle=False)\n",
                "\n",
                "submission = pd.read_csv(\"/opt/ml/input/data/eval/submission.csv\")\n",
                "# # 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
                "model.eval()\n",
                "\n",
                "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
                "all_predictions = []\n",
                "for images in tqdm(dataloader_validation):\n",
                "    with torch.no_grad():\n",
                "        images = images.to(device)\n",
                "        pred = model(images)\n",
                "        pred = pred.argmax(dim=-1)\n",
                "        all_predictions.extend(pred.cpu().numpy())\n",
                "\n",
                "submission = pd.read_csv(\"/opt/ml/input/data/eval/submission.csv\")\n",
                "submission['ans'] = all_predictions\n",
                "\n",
                "from pytz import timezone\n",
                "import datetime as dt\n",
                "# 제출할 파일을 저장합니다.\n",
                "now = (dt.datetime.now().astimezone(timezone(\"Asia/Seoul\")).strftime(\"%Y-%m-%d_%H%M%S\"))\n",
                "submission.to_csv(f\"/opt/ml/input/data/eval/submission_{now}.csv\", index=False)\n",
                "\n",
                "print('test inference is done!')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.5",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.5 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}