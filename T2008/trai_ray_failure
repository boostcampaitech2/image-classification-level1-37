{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "# data manipulation\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import math\n",
                "from collections import Counter, OrderedDict\n",
                "import random\n",
                "import os\n",
                "\n",
                "import torchvision\n",
                "from torchvision import transforms\n",
                "from albumentations import transforms as A\n",
                "from PIL import Image\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import DataLoader, Dataset\n",
                "\n",
                "from tqdm.notebook import tqdm\n",
                "from sklearn.model_selection import StratifiedKFold\n",
                "from sklearn.metrics import f1_score\n",
                "\n",
                "from maskdataset import MaskDataset\n",
                "from labeling import MakeLabel\n",
                "\n",
                "import ray\n",
                "from ray import tune\n",
                "from ray.tune import CLIReporter\n",
                "\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "# 오분류 데이터 재분류 후 csv 파일 생성\n",
                "path = {\"train_label\" : '/opt/ml/input/data/train/train_with_labels_fix_wrong_data.csv',\n",
                "        \"train_vanilla\" : '/opt/ml/input/data/train/train.csv'}\n",
                "\n",
                "wrong_data = {\"gender\" :  ['006359', '006360', '006361', '006362', '006363', '006364', '001498-1', '004432'],\n",
                "              \"mask\" : (['000020', '004418', '005227'], 'incollect_mask', 'normal')}\n",
                "\n",
                "train_label_fixed = MakeLabel(path=path, wrong_data=wrong_data)\n",
                "train_label_fixed.labeling()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "labeling된 csv 파일이 존재합니다.\n",
                        "파일명: train_label.csv \n",
                        " 파일경로: /opt/ml/input/data/train/train_with_labels_fix_wrong_data.csv\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "# 통제 변인 설명\n",
                "#1. imagenet_resnet50 model\n",
                "class MyModule(nn.Module):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.add_model = nn.Sequential(OrderedDict([\n",
                "            ('my_conv1', nn.Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
                "            ('batch', nn.BatchNorm2d(1024, eps = 1e-06, momentum = 0.1, affine=True, track_running_stats = True)),\n",
                "            ('relu', nn.ReLU()),\n",
                "            ('drop', nn.Dropout(p=0.5)),\n",
                "            ('my_conv2', nn.Conv2d(1024, 2048, kernel_size = (3,3), stride=(1,1), padding=(1,1), bias = False)),\n",
                "            ('batch2', nn.BatchNorm2d(2048, eps = 1e-06, momentum = 0.1, affine=True, track_running_stats = True)),\n",
                "            ('relu2', nn.ReLU()),\n",
                "            ('avgpool', nn.AdaptiveAvgPool2d(output_size = (1,1)))\n",
                "        ]))\n",
                "        self.fc_model = nn.Sequential(OrderedDict([\n",
                "            ('fc', nn.Linear(in_features = 2048, out_features = 18, bias = True))\n",
                "        ]))\n",
                "        self.pretrained =torchvision.models.resnet50(pretrained=True)\n",
                "        self.pretrained = nn.Sequential(*list(self.pretrained.children())[:-2])\n",
                "        self.my_model = nn.Sequential(\n",
                "            self.pretrained,\n",
                "            self.add_model,\n",
                "            self.fc_model\n",
                "        )\n",
                "        for _, layer in self.my_model[1].named_modules():\n",
                "            if isinstance(layer, nn.Conv2d):\n",
                "                nn.init.xavier_uniform_(layer.weight)\n",
                "        for _, layer in self.my_model[2].named_modules():\n",
                "            if isinstance(layer, nn.Linear):\n",
                "                nn.init.xavier_uniform_(layer.weight)\n",
                "                stdv = 1./math.sqrt(layer.weight.size(1))\n",
                "                layer.bias.data.uniform_(-stdv, stdv)\n",
                "        # print(self.my_model)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        x = self.my_model[0](x)\n",
                "        x = self.my_model[1](x)\n",
                "        x= x.view(-1,2048)\n",
                "        x = self.my_model[2](x)\n",
                "        return x\n",
                "\n",
                "#2 datatset\n",
                "class MaskDataset(Dataset):\n",
                "    def __init__(self, transform, image, label=None, train=True):\n",
                "        self.train = train\n",
                "        self.transform = transform\n",
                "        self.image = image\n",
                "        self.label = label\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.image)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        X = Image.open(self.image[idx])\n",
                "        X = self.transform(X)\n",
                "        if self.train:\n",
                "            y = self.label[idx]\n",
                "            return X,y\n",
                "        else:\n",
                "            return X"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "# 조작 변인\n",
                "#1. learning rate\n",
                "def get_adam_by_learningrate(model, learning_rate:float):\n",
                "    return torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
                "\n",
                "# 2. epoch\n",
                "def get_epoch_by_epoch(epoch:int):\n",
                "    return epoch\n",
                "\n",
                "# 3. batchsize 크기에 따른 데이터 로더 생성\n",
                "def get_dataloaders_by_batchsize(dataset, batch_size:int, num_workers:int=2, shuffle:bool=False, drop_last=True):\n",
                "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, drop_last=drop_last)\n",
                "    "
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "# ray 탐색 범위 설정\n",
                "config_space={\n",
                "    \"NUM_EPOCH\" : tune.choice([4,5,6,7,8,9,10]),\n",
                "    \"LearningRate\" : tune.uniform(0.0001,0.001), #low, high\n",
                "    \"BatchSize\" : tune.choice([8,16]),\n",
                "    \"NUM_WORKERS\" : tune.choice([2,3,4]),\n",
                "    \n",
                "}\n",
                "\n",
                "# train & test trainsform\n",
                "transform_list = {\n",
                "    \"train\" : torchvision.transforms.Compose([\n",
                "        transforms.Resize((224,224)),\n",
                "        transforms.ToTensor(),\n",
                "        # A.ChannelShuffle(p=0.5), #Randomly rearrange channels of the input RGB image.\n",
                "        # A.RGBShift(always_apply=False, p=0.5, r_shift_limit=(-22, 20), g_shift_limit=(-20, 20), b_shift_limit=(-20, 20)),#Randomly shift values for each channel of the input RGB image.\n",
                "        # A.CoarseDropout(min_holes = 10, max_holes=100,p=0.5), #CoarseDropout of the rectangular regions in the image.\n",
                "        transforms.RandomHorizontalFlip(p=0.5),\n",
                "        transforms.Normalize(mean=[0.558,0.512,0.478], std = [0.218,0.238,0.252])]),\n",
                "    \n",
                "    \"test\": torchvision.transforms.Compose([\n",
                "        transforms.Resize((224,224)),\n",
                "        transforms.ToTensor(),\n",
                "        transforms.Normalize(mean=[0.558,0.512,0.478], std = [0.218,0.238,0.252])])}"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "train_eval_csv = pd.read_csv(\"/opt/ml/input/data/train/train_with_labels_fix_wrong_data.csv\")\n",
                "images = train_eval_csv[\"img_path\"]\n",
                "labels = train_eval_csv[\"label\"]\n",
                "\n",
                "# test_csv = pd.read_csv(\"/opt/ml/input/data/eval/info.csv\")\n",
                "# images_test = test_csv[\"ImageID\"]\n",
                "\n",
                "#통제 변인\n",
                "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #학습 때 GPU 사용여부 결정\n",
                "\n",
                "train_images, train_labels = images, labels\n",
                "eval_images, eval_labels = images, labels\n",
                "train_dataset = MaskDataset(transform_list[\"train\"], train_images, label=train_labels, train=True)\n",
                "eval_dataset = MaskDataset(transform_list[\"test\"], eval_images, label=eval_labels, train=True) # test형태로 transform 적용\n",
                "\n",
                "train_dataloader = get_dataloaders_by_batchsize(dataset=train_dataset,batch_size=16,num_workers=2, shuffle=True)\n",
                "eval_dataloader = get_dataloaders_by_batchsize(dataset=eval_dataset,batch_size=None,shuffle=False, drop_last=False)\n",
                "SKF = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
                "\n",
                "t,v = [], []\n",
                "a,b= next(iter(SKF.split(images,labels)))\n",
                "\n",
                "    \n",
                "    # t.append([a])\n",
                "    # v.append([b])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "# Set random seed\n",
                "SEED = 2021\n",
                "random.seed(SEED)\n",
                "np.random.seed(SEED)\n",
                "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
                "torch.manual_seed(SEED)\n",
                "torch.cuda.manual_seed(SEED)  # type: ignore\n",
                "torch.backends.cudnn.deterministic = True  # type: ignore\n",
                "torch.backends.cudnn.benchmark = True  # type: ignore\n",
                "\n",
                "torch.cuda.empty_cache()\n",
                "def training(\n",
                "    config #조작변인 lr, epoch, batchsize\n",
                "):\n",
                "    # data load\n",
                "    train_eval_csv = pd.read_csv(\"/opt/ml/input/data/train/train_with_labels_fix_wrong_data.csv\")\n",
                "    images = train_eval_csv[\"img_path\"]\n",
                "    labels = train_eval_csv[\"label\"]\n",
                "\n",
                "    # test_csv = pd.read_csv(\"/opt/ml/input/data/eval/info.csv\")\n",
                "    # images_test = test_csv[\"ImageID\"]\n",
                "    \n",
                "    #통제 변인\n",
                "    target_model = MyModule()\n",
                "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #학습 때 GPU 사용여부 결정\n",
                "    target_model.to(device)\n",
                "    SKF = StratifiedKFold(n_splits=5,shuffle=True,random_state=SEED)\n",
                "\n",
                "    # optimizer weights\n",
                "    class_weights = [v for _, v in sorted(Counter(labels).items())]\n",
                "    class_weights = list(map(lambda x : 1-x/sum(class_weights),class_weights))\n",
                "    class_weights = torch.FloatTensor(class_weights).to(device)\n",
                "    loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
                "\n",
                "    #학습 시작\n",
                "    best_f1_score = 0\n",
                "    best_loss = 9999\n",
                "    best_acc = 0\n",
                "    \n",
                "    for train_idx, eval_idx in SKF.split(images, labels): # folds 개수만큼 반복\n",
                "        #조작 변인\n",
                "        NUM_EPOCH = get_epoch_by_epoch(config[\"NUM_EPOCH\"])\n",
                "        optimizer = get_adam_by_learningrate(target_model, learning_rate=config[\"LearningRate\"])\n",
                "\n",
                "\n",
                "        train_images, train_labels = images[train_idx], labels[train_idx]\n",
                "        eval_images, eval_labels = images[train_idx], labels[eval_idx]\n",
                "        train_dataset = MaskDataset(transform_list[\"train\"], train_images, label=train_labels, train=True)\n",
                "        eval_dataset = MaskDataset(transform_list[\"test\"], eval_images, label=eval_labels, train=True) # test형태로 transform 적용\n",
                "\n",
                "        train_dataloader = get_dataloaders_by_batchsize(dataset=train_dataset,batch_size=config[\"BatchSize\"],num_workers=config[\"NUM_WORKERS\"], shuffle=True,drop_last=True,)\n",
                "        eval_dataloader = get_dataloaders_by_batchsize(dataset=eval_dataset,batch_size=1,shuffle=False,drop_last=False)\n",
                "\n",
                "        for epoch in range(NUM_EPOCH): # epoch 횟수만큼 반복\n",
                "\n",
                "            for phase in [\"train\",\"test\"]:\n",
                "                running_acc = 0\n",
                "                running_loss = 0\n",
                "                running_f1score = 0\n",
                "\n",
                "                if phase == \"train\":\n",
                "                    dataloader = train_dataloader\n",
                "                    target_model.train()\n",
                "                else:\n",
                "                    dataloader = eval_dataloader\n",
                "                    target_model.eval()\n",
                "\n",
                "                for idx, (images_tmp,labels_tmp) in enumerate(tqdm(dataloader)):\n",
                "                    images_tmp = images_tmp.to(device)\n",
                "                    labels_tmp = labels_tmp.to(device)\n",
                "\n",
                "                    optimizer.zero_grad()\n",
                "                    with torch.set_grad_enabled(phase==\"train\"):\n",
                "                        logits = target_model(images_tmp)\n",
                "                        _, preds = torch.max(logits,dim=1)\n",
                "                        loss = loss_fn(logits,labels_tmp)\n",
                "                    \n",
                "                    if phase==\"train\":\n",
                "                        loss.backward()\n",
                "                        optimizer.step()\n",
                "\n",
                "                    f1score = f1_score(labels.cpu(),preds.cpu(),average=\"macro\")\n",
                "            \n",
                "                    running_acc += sum(labels.cpu()==preds.cpu())\n",
                "                    running_loss += loss.item() * images.size(0)\n",
                "                    running_f1score += f1score # 각 batch별로 f1 score 계산\n",
                "                \n",
                "                if phase==\"test\":\n",
                "                    accuracy_ = running_acc / len(dataloader.dataset)\n",
                "                    f1score_ = running_f1score/(idx+1) \n",
                "                    loss_ = running_loss / len(dataloader.dataset)\n",
                "            \n",
                "            if best_f1_score < f1score_:\n",
                "                best_f1_score = f1score_\n",
                "                best_loss = loss_\n",
                "                best_acc = accuracy_\n",
                "    # epoch 종료\n",
                "    tune.report(f1score=best_f1_score, accuracy=best_acc, loss=best_loss)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "from tqdm import tqdm, notebook\n",
                "NUM_TRIAL = 2 # Hyper Parameter를 탐색할 때에, 실험을 최대 수행할 횟수를 지정합니다.\n",
                "\n",
                "reporter = CLIReporter( # jupyter notebook을 사용하기 때문에 중간 수행 결과를 command line에 출력하도록 함\n",
                "    parameter_columns=[\"NUM_EPOCH\", \"LearningRate\", \"BatchSize\",\"NUM_WORKERS\"],\n",
                "    metric_columns=[\"f1score\",\"accuracy\", \"loss\"])\n",
                "\n",
                "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
                "\n",
                "optim = HyperOptSearch( # HyperOptSearch 통해 Search를 진행합니다. 더 다양한 Optimizer들은 https://docs.ray.io/en/master/tune/api_docs/suggestion.html#bayesopt 문서를 참고해주세요\n",
                "    metric='f1score', # hyper parameter tuning 시 최적화할 metric을 결정합니다. 본 실험은 test accuracy를 target으로 합니다\n",
                "    mode=\"max\",  # target objective를 maximize 하는 것을 목표로 설정합니다\n",
                " )\n",
                "\n",
                "ray.shutdown() # ray 초기화 후 실행\n",
                "ray.init(num_cpus=4,num_gpus=1)\n",
                "# ray.init(address=\"ray://101.101.209.250:2223\")\n",
                "# ray.init()\n",
                "analysis = tune.run(,\n",
                "    training,\n",
                "    config=config_space,\n",
                "    search_alg=optim,\n",
                "    #verbose=1,\n",
                "    progress_reporter=reporter,\n",
                "    num_samples=NUM_TRIAL,\n",
                "    resources_per_trial={'gpu':0,'cpu':1} # GPU를 사용하지 않는다면 comment 처리로 지워주세요\n",
                ")\n",
                "\n",
                "# 실행하면 시간이 걸려요! NUM_TRIAL를 줄여보시거나, 커피를 마시고 오세요 :)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "2021-08-27 11:11:22,796\tINFO services.py:1263 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
                        "2021-08-27 11:11:22,799\tWARNING services.py:1749 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 1064042496 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
                        "2021-08-27 11:11:23,581\tWARNING function_runner.py:558 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
                        "2021-08-27 11:11:23,886\tERROR syncer.py:72 -- Log sync requires rsync to be installed.\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "== Status ==\n",
                        "Memory usage on this node: 6.0/88.5 GiB\n",
                        "Using FIFO scheduling algorithm.\n",
                        "Resources requested: 0/4 CPUs, 0/1 GPUs, 0.0/66.54 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:V100)\n",
                        "Result logdir: /opt/ml/ray_results/training_2021-08-27_11-11-23\n",
                        "Number of trials: 1/2 (1 PENDING)\n",
                        "+-------------------+----------+-------+-------------+----------------+-------------+---------------+\n",
                        "| Trial name        | status   | loc   |   NUM_EPOCH |   LearningRate |   BatchSize |   NUM_WORKERS |\n",
                        "|-------------------+----------+-------+-------------+----------------+-------------+---------------|\n",
                        "| training_83c46aae | PENDING  |       |           4 |    0.000104031 |           8 |             3 |\n",
                        "+-------------------+----------+-------+-------------+----------------+-------------+---------------+\n",
                        "\n",
                        "\n",
                        "== Status ==\n",
                        "Memory usage on this node: 7.8/88.5 GiB\n",
                        "Using FIFO scheduling algorithm.\n",
                        "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/66.54 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:V100)\n",
                        "Result logdir: /opt/ml/ray_results/training_2021-08-27_11-11-23\n",
                        "Number of trials: 2/2 (1 PENDING, 1 RUNNING)\n",
                        "+-------------------+----------+-------+-------------+----------------+-------------+---------------+\n",
                        "| Trial name        | status   | loc   |   NUM_EPOCH |   LearningRate |   BatchSize |   NUM_WORKERS |\n",
                        "|-------------------+----------+-------+-------------+----------------+-------------+---------------|\n",
                        "| training_83c46aae | RUNNING  |       |           4 |    0.000104031 |           8 |             3 |\n",
                        "| training_83da306e | PENDING  |       |          10 |    0.000538184 |          16 |             3 |\n",
                        "+-------------------+----------+-------+-------------+----------------+-------------+---------------+\n",
                        "\n",
                        "\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "  0%|          | 0/1890 [00:00<?, ?it/s]\n",
                        "  0%|          | 0/1890 [00:00<?, ?it/s]\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m 2021-08-27 11:11:30,479\tERROR function_runner.py:266 -- Runner Thread raised error.\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m Traceback (most recent call last):\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 260, in run\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m     self._entrypoint()\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 328, in entrypoint\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m     return self._trainable_func(self.config, self._status_reporter,\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 594, in _trainable_func\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m     output = fn()\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m   File \"<ipython-input-7-838d50e97d1c>\", line 82, in training\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/pandas/core/generic.py\", line 5478, in __getattr__\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m     return object.__getattribute__(self, name)\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m AttributeError: 'Series' object has no attribute 'cpu'\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m Exception in thread Thread-2:\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m Traceback (most recent call last):\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m   File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m     self.run()\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 279, in run\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m     raise e\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 260, in run\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m     self._entrypoint()\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 328, in entrypoint\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m     return self._trainable_func(self.config, self._status_reporter,\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 594, in _trainable_func\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m     output = fn()\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m   File \"<ipython-input-7-838d50e97d1c>\", line 82, in training\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/pandas/core/generic.py\", line 5478, in __getattr__\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m     return object.__getattribute__(self, name)\n",
                        "\u001b[2m\u001b[36m(pid=16057)\u001b[0m AttributeError: 'Series' object has no attribute 'cpu'\n",
                        "2021-08-27 11:11:30,668\tERROR trial_runner.py:773 -- Trial training_83c46aae: Error processing event.\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 739, in _process_trial\n",
                        "    results = self.trial_executor.fetch_result(trial)\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 746, in fetch_result\n",
                        "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 82, in wrapper\n",
                        "    return func(*args, **kwargs)\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/ray/worker.py\", line 1621, in get\n",
                        "    raise value.as_instanceof_cause()\n",
                        "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=16057, ip=172.17.0.2, repr=<ray.tune.function_runner.ImplicitFunc object at 0x7f145144db80>)\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/ray/tune/trainable.py\", line 178, in train_buffered\n",
                        "    result = self.train()\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/ray/tune/trainable.py\", line 237, in train\n",
                        "    result = self.step()\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 379, in step\n",
                        "    self._report_thread_runner_error(block=True)\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 526, in _report_thread_runner_error\n",
                        "    raise TuneError(\n",
                        "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
                        "\u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=16057, ip=172.17.0.2, repr=<ray.tune.function_runner.ImplicitFunc object at 0x7f145144db80>)\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 260, in run\n",
                        "    self._entrypoint()\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 328, in entrypoint\n",
                        "    return self._trainable_func(self.config, self._status_reporter,\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 594, in _trainable_func\n",
                        "    output = fn()\n",
                        "  File \"<ipython-input-7-838d50e97d1c>\", line 82, in training\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/pandas/core/generic.py\", line 5478, in __getattr__\n",
                        "    return object.__getattribute__(self, name)\n",
                        "AttributeError: 'Series' object has no attribute 'cpu'\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Result for training_83c46aae:\n",
                        "  {}\n",
                        "  \n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "  0%|          | 0/945 [00:00<?, ?it/s]\n",
                        "2021-08-27 11:11:36,682\tERROR trial_runner.py:773 -- Trial training_83da306e: Error processing event.\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 739, in _process_trial\n",
                        "    results = self.trial_executor.fetch_result(trial)\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 746, in fetch_result\n",
                        "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 82, in wrapper\n",
                        "    return func(*args, **kwargs)\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/ray/worker.py\", line 1621, in get\n",
                        "    raise value.as_instanceof_cause()\n",
                        "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=16060, ip=172.17.0.2, repr=<ray.tune.function_runner.ImplicitFunc object at 0x7fef3daae9a0>)\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/ray/tune/trainable.py\", line 178, in train_buffered\n",
                        "    result = self.train()\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/ray/tune/trainable.py\", line 237, in train\n",
                        "    result = self.step()\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 379, in step\n",
                        "    self._report_thread_runner_error(block=True)\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 526, in _report_thread_runner_error\n",
                        "    raise TuneError(\n",
                        "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
                        "\u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=16060, ip=172.17.0.2, repr=<ray.tune.function_runner.ImplicitFunc object at 0x7fef3daae9a0>)\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 260, in run\n",
                        "    self._entrypoint()\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 328, in entrypoint\n",
                        "    return self._trainable_func(self.config, self._status_reporter,\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 594, in _trainable_func\n",
                        "    output = fn()\n",
                        "  File \"<ipython-input-7-838d50e97d1c>\", line 68, in training\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/tqdm/std.py\", line 1171, in __iter__\n",
                        "    for obj in iterable:\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 435, in __next__\n",
                        "    data = self._next_data()\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1085, in _next_data\n",
                        "    return self._process_data(data)\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1111, in _process_data\n",
                        "    data.reraise()\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/torch/_utils.py\", line 428, in reraise\n",
                        "    raise self.exc_type(msg)\n",
                        "KeyError: Caught KeyError in DataLoader worker process 0.\n",
                        "Original Traceback (most recent call last):\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3361, in get_loc\n",
                        "    return self._engine.get_loc(casted_key)\n",
                        "  File \"pandas/_libs/index.pyx\", line 76, in pandas._libs.index.IndexEngine.get_loc\n",
                        "  File \"pandas/_libs/index.pyx\", line 108, in pandas._libs.index.IndexEngine.get_loc\n",
                        "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 2131, in pandas._libs.hashtable.Int64HashTable.get_item\n",
                        "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 2140, in pandas._libs.hashtable.Int64HashTable.get_item\n",
                        "KeyError: 4758\n",
                        "\n",
                        "The above exception was the direct cause of the following exception:\n",
                        "\n",
                        "\u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=16060, ip=172.17.0.2, repr=<ray.tune.function_runner.ImplicitFunc object at 0x7fef3daae9a0>)\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n",
                        "    data = fetcher.fetch(index)\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
                        "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
                        "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
                        "  File \"<ipython-input-3-5177f6a09ebe>\", line 55, in __getitem__\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/pandas/core/series.py\", line 942, in __getitem__\n",
                        "    return self._get_value(key)\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/pandas/core/series.py\", line 1051, in _get_value\n",
                        "    loc = self.index.get_loc(label)\n",
                        "  File \"/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3363, in get_loc\n",
                        "    raise KeyError(key) from err\n",
                        "KeyError: 4758\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Result for training_83da306e:\n",
                        "  {}\n",
                        "  \n",
                        "== Status ==\n",
                        "Memory usage on this node: 7.9/88.5 GiB\n",
                        "Using FIFO scheduling algorithm.\n",
                        "Resources requested: 0/4 CPUs, 0/1 GPUs, 0.0/66.54 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:V100)\n",
                        "Result logdir: /opt/ml/ray_results/training_2021-08-27_11-11-23\n",
                        "Number of trials: 2/2 (2 ERROR)\n",
                        "+-------------------+----------+-------+-------------+----------------+-------------+---------------+\n",
                        "| Trial name        | status   | loc   |   NUM_EPOCH |   LearningRate |   BatchSize |   NUM_WORKERS |\n",
                        "|-------------------+----------+-------+-------------+----------------+-------------+---------------|\n",
                        "| training_83c46aae | ERROR    |       |           4 |    0.000104031 |           8 |             3 |\n",
                        "| training_83da306e | ERROR    |       |          10 |    0.000538184 |          16 |             3 |\n",
                        "+-------------------+----------+-------+-------------+----------------+-------------+---------------+\n",
                        "Number of errored trials: 2\n",
                        "+-------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
                        "| Trial name        |   # failures | error file                                                                                                                                                         |\n",
                        "|-------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
                        "| training_83c46aae |            1 | /opt/ml/ray_results/training_2021-08-27_11-11-23/training_83c46aae_1_BatchSize=8,LearningRate=0.00010403,NUM_EPOCH=4,NUM_WORKERS=3_2021-08-27_11-11-23/error.txt   |\n",
                        "| training_83da306e |            1 | /opt/ml/ray_results/training_2021-08-27_11-11-23/training_83da306e_2_BatchSize=16,LearningRate=0.00053818,NUM_EPOCH=10,NUM_WORKERS=3_2021-08-27_11-11-23/error.txt |\n",
                        "+-------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
                        "\n",
                        "== Status ==\n",
                        "Memory usage on this node: 7.9/88.5 GiB\n",
                        "Using FIFO scheduling algorithm.\n",
                        "Resources requested: 0/4 CPUs, 0/1 GPUs, 0.0/66.54 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:V100)\n",
                        "Result logdir: /opt/ml/ray_results/training_2021-08-27_11-11-23\n",
                        "Number of trials: 2/2 (2 ERROR)\n",
                        "+-------------------+----------+-------+-------------+----------------+-------------+---------------+\n",
                        "| Trial name        | status   | loc   |   NUM_EPOCH |   LearningRate |   BatchSize |   NUM_WORKERS |\n",
                        "|-------------------+----------+-------+-------------+----------------+-------------+---------------|\n",
                        "| training_83c46aae | ERROR    |       |           4 |    0.000104031 |           8 |             3 |\n",
                        "| training_83da306e | ERROR    |       |          10 |    0.000538184 |          16 |             3 |\n",
                        "+-------------------+----------+-------+-------------+----------------+-------------+---------------+\n",
                        "Number of errored trials: 2\n",
                        "+-------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
                        "| Trial name        |   # failures | error file                                                                                                                                                         |\n",
                        "|-------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
                        "| training_83c46aae |            1 | /opt/ml/ray_results/training_2021-08-27_11-11-23/training_83c46aae_1_BatchSize=8,LearningRate=0.00010403,NUM_EPOCH=4,NUM_WORKERS=3_2021-08-27_11-11-23/error.txt   |\n",
                        "| training_83da306e |            1 | /opt/ml/ray_results/training_2021-08-27_11-11-23/training_83da306e_2_BatchSize=16,LearningRate=0.00053818,NUM_EPOCH=10,NUM_WORKERS=3_2021-08-27_11-11-23/error.txt |\n",
                        "+-------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
                        "\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "  0%|          | 0/945 [00:00<?, ?it/s]\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m 2021-08-27 11:11:36,618\tERROR function_runner.py:266 -- Runner Thread raised error.\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m Traceback (most recent call last):\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 260, in run\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     self._entrypoint()\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 328, in entrypoint\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     return self._trainable_func(self.config, self._status_reporter,\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 594, in _trainable_func\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     output = fn()\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"<ipython-input-7-838d50e97d1c>\", line 68, in training\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/tqdm/std.py\", line 1171, in __iter__\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     for obj in iterable:\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 435, in __next__\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     data = self._next_data()\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1085, in _next_data\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     return self._process_data(data)\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1111, in _process_data\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     data.reraise()\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/torch/_utils.py\", line 428, in reraise\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     raise self.exc_type(msg)\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m KeyError: Caught KeyError in DataLoader worker process 0.\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m Original Traceback (most recent call last):\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3361, in get_loc\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     return self._engine.get_loc(casted_key)\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"pandas/_libs/index.pyx\", line 76, in pandas._libs.index.IndexEngine.get_loc\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"pandas/_libs/index.pyx\", line 108, in pandas._libs.index.IndexEngine.get_loc\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"pandas/_libs/hashtable_class_helper.pxi\", line 2131, in pandas._libs.hashtable.Int64HashTable.get_item\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"pandas/_libs/hashtable_class_helper.pxi\", line 2140, in pandas._libs.hashtable.Int64HashTable.get_item\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m KeyError: 4758\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m \n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m The above exception was the direct cause of the following exception:\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m \n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m Traceback (most recent call last):\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     data = fetcher.fetch(index)\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"<ipython-input-3-5177f6a09ebe>\", line 55, in __getitem__\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/pandas/core/series.py\", line 942, in __getitem__\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     return self._get_value(key)\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/pandas/core/series.py\", line 1051, in _get_value\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     loc = self.index.get_loc(label)\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3363, in get_loc\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     raise KeyError(key) from err\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m KeyError: 4758\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m \n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m Exception in thread Thread-2:\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m Traceback (most recent call last):\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     self.run()\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 279, in run\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     raise e\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 260, in run\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     self._entrypoint()\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 328, in entrypoint\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     return self._trainable_func(self.config, self._status_reporter,\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 594, in _trainable_func\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     output = fn()\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"<ipython-input-7-838d50e97d1c>\", line 68, in training\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/tqdm/std.py\", line 1171, in __iter__\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     for obj in iterable:\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 435, in __next__\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     data = self._next_data()\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1085, in _next_data\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     return self._process_data(data)\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1111, in _process_data\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     data.reraise()\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/torch/_utils.py\", line 428, in reraise\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     raise self.exc_type(msg)\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m KeyError: Caught KeyError in DataLoader worker process 0.\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m Original Traceback (most recent call last):\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3361, in get_loc\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     return self._engine.get_loc(casted_key)\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"pandas/_libs/index.pyx\", line 76, in pandas._libs.index.IndexEngine.get_loc\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"pandas/_libs/index.pyx\", line 108, in pandas._libs.index.IndexEngine.get_loc\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"pandas/_libs/hashtable_class_helper.pxi\", line 2131, in pandas._libs.hashtable.Int64HashTable.get_item\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"pandas/_libs/hashtable_class_helper.pxi\", line 2140, in pandas._libs.hashtable.Int64HashTable.get_item\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m KeyError: 4758\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m \n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m The above exception was the direct cause of the following exception:\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m \n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m Traceback (most recent call last):\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     data = fetcher.fetch(index)\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"<ipython-input-3-5177f6a09ebe>\", line 55, in __getitem__\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/pandas/core/series.py\", line 942, in __getitem__\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     return self._get_value(key)\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/pandas/core/series.py\", line 1051, in _get_value\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     loc = self.index.get_loc(label)\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m   File \"/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3363, in get_loc\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m     raise KeyError(key) from err\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m KeyError: 4758\n",
                        "\u001b[2m\u001b[36m(pid=16060)\u001b[0m \n"
                    ]
                },
                {
                    "output_type": "error",
                    "ename": "TuneError",
                    "evalue": "('Trials did not complete', [training_83c46aae, training_83da306e])",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-8-680c1daec6f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# ray.init(address=\"ray://101.101.209.250:2223\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# ray.init()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m analysis = tune.run(\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, loggers, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint, _remote)\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [training_83c46aae, training_83da306e])"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "best_trial = analysis.get_best_trial('accuracy', 'max')\n",
                "print(f\"최고 성능 config : {best_trial.config}\")\n",
                "print(f\"최고 test accuracy : {best_trial.last_result['accuracy']}\")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "from maskdataset import MaskDataset\n",
                "transform=transforms.Compose([\n",
                "            # transforms.Resize((224,384), Image.BILINEAR),\n",
                "            transforms.ToTensor(),\n",
                "            transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.2,0.2,0.2))\n",
                "            ])\n",
                "\n",
                "\n",
                "validation_dataset = MaskDataset(transform=transform, train=False)\n",
                "dataloader_validation = DataLoader(dataset=validation_dataset,\n",
                "                                   shuffle=False)\n",
                "\n",
                "\n",
                "\n",
                "submission = pd.read_csv(\"/opt/ml/input/data/eval/submission.csv\")\n",
                "# # 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
                "model.eval()\n",
                "\n",
                "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
                "all_predictions = []\n",
                "for images in tqdm(dataloader_validation):\n",
                "    with torch.no_grad():\n",
                "        images = images.to(device)\n",
                "        pred = model(images)\n",
                "        pred = pred.argmax(dim=-1)\n",
                "        all_predictions.extend(pred.cpu().numpy())\n",
                "\n",
                "submission = pd.read_csv(\"/opt/ml/input/data/eval/submission.csv\")\n",
                "submission['ans'] = all_predictions\n",
                "\n",
                "from pytz import timezone\n",
                "import datetime as dt\n",
                "# 제출할 파일을 저장합니다.\n",
                "now = (dt.datetime.now().astimezone(timezone(\"Asia/Seoul\")).strftime(\"%Y-%m-%d_%H%M%S\"))\n",
                "submission.to_csv(f\"/opt/ml/input/data/eval/submission_{now}.csv\", index=False)\n",
                "\n",
                "print('test inference is done!')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.5",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.5 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}