{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16afe1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from adamp import AdamP\n",
    "from tqdm import tqdm, notebook\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# random seed\n",
    "seed = 37\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(f'seed : {seed}')\n",
    "\n",
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device : {device}')\n",
    "print(torch.cuda.get_device_properties(device))\n",
    "\n",
    "# current working directory\n",
    "cwd = os.getcwd()\n",
    "print(f' current working direcory : {cwd}')\n",
    "\n",
    "# Training data will be stored in this folder\n",
    "name = 'restoration_final_dropout' # 경로 이름 지정\n",
    "if not os.path.isdir(f'data_file/{name}') :\n",
    "    os.chdir(os.path.join(cwd, 'data_file'))\n",
    "    os.mkdir(f'{name}')\n",
    "    os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde79206",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('input/data/train/images')\n",
    "image_dirs = [str(x) for x in list(path.glob('*')) if '._' not in str(x)]\n",
    "# 'input/data/train/images/003277_female_Asian_19' 이런 형태가 나온다.\n",
    "# np.array 형식으로 변환\n",
    "image_dirs = np.array(image_dirs)\n",
    "\n",
    "# 나이와 성별 구분이 문제니까 이 두 개를 기준으로 나눠서 stratified_kfold를 사용하면 imbalance를 조금 방지할 수 있지 않을까?\n",
    "# 나이 성별 정보면 이용해서 데이터 나누기\n",
    "# 나이가 60세 이상 정보가 너무 부족하니까 학습시에 나이 58을 기준으로 나눠서 진행\n",
    "\n",
    "def label_fold(image_dirs):\n",
    "    stratified_kfold_label = []\n",
    "    for image_dir in image_dirs :\n",
    "        cnt = 0\n",
    "        if 'female' in image_dir : cnt += 3\n",
    "        else : cnt += 0 \n",
    "        \n",
    "        age = int(image_dir.split('_')[3][:2])\n",
    "        if age < 30 : cnt += 0\n",
    "        elif age < 58 : cnt += 1\n",
    "        else : cnt += 2\n",
    "        stratified_kfold_label.append(cnt)\n",
    "    stratified_kfold_label = np.array(stratified_kfold_label)\n",
    "    stratified_kfold = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "    # Stratified K-Fold는 층화된 folds를 반환하는 기존 K-Fold의 변형된 방식이다. 각 집합에는 전체 집합과 거의 동일하게 클래스의 표본 비율이 포함된다. \n",
    "    # 불균형 클래스의 경우 사용을 많이 한다. 이를 통해 데이터별로 가지는 클래스의 분포를 맞춰줄 수 있을 것으로 기대한다.\n",
    "    # train에 2700개의 id 중에서 4/5가 들어가고 valid에 1/5가 들어간다. 이걸 다른 모양으로 train할 때 다섯번 반복하게 된다.\n",
    "    fold_list = []\n",
    "    for train_data, valid_data in stratified_kfold.split(image_dirs, stratified_kfold_label) :\n",
    "        fold_list.append({'train':train_data, 'valid':valid_data})\n",
    "    return fold_list\n",
    "\n",
    "fold_list = label_fold(image_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbac6573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Mask까지 포함해서, 다시 라벨링해서 원래 데이터 class로 맞춰준다.\n",
    "def label_func(image_paths) :\n",
    "        cnt = 0\n",
    "        if 'normal' in image_paths : cnt += 12\n",
    "        elif 'incorrect_mask' in image_paths : cnt += 6\n",
    "        else : cnt += 0\n",
    "\n",
    "        if 'female' in image_paths : cnt += 3\n",
    "        else : cnt += 0\n",
    "\n",
    "        age = int(image_paths.split('_')[3][:2])\n",
    "        if age < 30 : cnt += 0\n",
    "        elif age < 58 : cnt += 1\n",
    "        else : cnt += 2\n",
    "\n",
    "        return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458581b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class MaskDataset(Dataset) :\n",
    "    # image_paths는 path input/data/train/images/003277_female_Asian_19/mask3.jpg 이런 식으로 들어온다.\n",
    "    def __init__(self, image_paths, transform, augment = None, train_TF = False):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "        self.train_TF = train_TF\n",
    "        \n",
    "    def __len__(self) :\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = np.array(Image.open(self.image_paths[idx]))\n",
    "        \n",
    "        if self.augment: # augmentation하는 경우에\n",
    "            image = self.transform(self.augment(image = image)['image'])\n",
    "        else:    \n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.train_TF : # 트레이닝하는 경우\n",
    "            label = label_func(self.image_paths[idx])\n",
    "            return {'image' : image, 'label' : label}\n",
    "            \n",
    "        else:\n",
    "            return {'image' : image}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc884bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform\n",
    "'''\n",
    "transforms.ToPILImage() - csv 파일로 데이터셋을 받을 경우, PIL image로 바꿔준다.\n",
    "transforms.CenterCrop(size) - 가운데 부분을 size 크기로 자른다.\n",
    "transforms.Grayscale(num_output_channels=1) - grayscale로 변환한다.\n",
    "transforms.RandomAffine(degrees) - 랜덤으로 affine 변형을 한다.\n",
    "transforms.RandomCrop(size) -이미지를 랜덤으로 아무데나 잘라 size 크기로 출력한다.\n",
    "transforms.RandomResizedCrop(size) - 이미지 사이즈를 size로 변경한다\n",
    "transforms.Resize(size) - 이미지 사이즈를 size로 변경한다\n",
    "transforms.RandomRotation(degrees) 이미지를 랜덤으로 degrees 각도로 회전한다.\n",
    "transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333)) - 이미지를 랜덤으로 변형한다.\n",
    "transforms.RandomVerticalFlip(p=0.5) - 이미지를 랜덤으로 수직으로 뒤집는다. p =0이면 뒤집지 않는다.\n",
    "transforms.RandomHorizontalFlip(p=0.5) - 이미지를 랜덤으로 수평으로 뒤집는다.\n",
    "transforms.ToTensor() - 이미지 데이터를 tensor로 바꿔준다.\n",
    "transforms.Normalize(mean, std, inplace=False) - 이미지를 정규화한다.\n",
    "'''\n",
    "# centercrop을 통해 얼굴에서 벗어나는 부분을 줄여준다. \n",
    "# 멘토님이 중요하게 augmentation해야 한다한 부분 중, rotation, flip이 이미지 데이터 생긴 형태와 가장 잘 맞는다고 판단해서 이 두개로 진행\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.CenterCrop([300,250]),\n",
    "    T.RandomRotation(10),\n",
    "    T.RandomHorizontalFlip(0.5),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246))\n",
    "])\n",
    "\n",
    "# valid_transform에서는 기본적인 것만 가져가고 augmentation한 것을 빼고 검증을 거친다.\n",
    "valid_transform = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.CenterCrop([300,250]),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.56, 0.51, 0.48), std=(0.22, 0.24, 0.25))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1812210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "# -- model\n",
    "# 왜 relu를 이걸 만들 때 넣었는지 모르겠지만 생각보다 잘 동작하긴 했다.\n",
    "# efficientnet 중에서 파라미터 수가 적당하고 성능도 괜찮은 b3, b4로 테스트를 진행했다.\n",
    "class Myeff4Model(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.model_name = EfficientNet.from_pretrained('efficientnet-b4', \n",
    "                                                in_channels=3, \n",
    "                                                num_classes=18) # weight가져오고 num_classes(두번째 파라미터로 학습시키는 class 수)\n",
    "        self.model_name._dropout = nn.Dropout(p=0.7, inplace=False)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x = F.relu(self.model_name(x))\n",
    "        return x\n",
    "\n",
    "    \n",
    "class Myeff3Model(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.model_name = EfficientNet.from_pretrained('efficientnet-b3', \n",
    "                                                in_channels=3, \n",
    "                                                num_classes=18) # weight가져오고 num_classes(두번째 파라미터로 학습시키는 class 수)\n",
    "    def forward(self, x) :\n",
    "        x = F.relu(self.model_name(x))\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dea0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "batch_size = 16\n",
    "lr = 1e-4\n",
    "epochs = 10\n",
    "\n",
    "counter = 0\n",
    "patience = 10\n",
    "accumulation_steps = 2\n",
    "best_val_acc = 0\n",
    "best_val_loss = np.inf\n",
    "lr_decay_step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf42e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validating\n",
    "\n",
    "folds_index = [1, 2, 3, 4, 5] # 총 5개\n",
    "\n",
    "for fold in folds_index :\n",
    "    print(f'Fold number {fold}')\n",
    "    min_loss = 3\n",
    "    early_stop = 0\n",
    "\n",
    "# -- kfold를 이용해서 dataset을 만들기 위한 경로 리스트\n",
    "    train_image_paths, valid_image_paths = [], []\n",
    "\n",
    "    # -- train_data\n",
    "    for train_dir in image_dirs[fold_list[fold-1]['train']] :\n",
    "        train_image_paths.extend(glob(train_dir+'/*'))\n",
    "    train_dataset = MaskDataset(train_image_paths, train_transform, train_TF=True)\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "    \n",
    "    # -- valid_data\n",
    "    for valid_dir in image_dirs[fold_list[fold-1]['valid']] :\n",
    "        valid_image_paths.extend(glob(valid_dir+'/*'))\n",
    "    valid_dataset = MaskDataset(valid_image_paths, valid_transform, train_TF=True)\n",
    "    valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size//4, shuffle=True, num_workers=3)\n",
    "    \n",
    "    # -- model\n",
    "    model = MyModel()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # -- loss & metric\n",
    "    optimizer = AdamP(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    scheduler = StepLR(optimizer, lr_decay_step, gamma=0.5)\n",
    "\n",
    "    # -- logging\n",
    "    logger = SummaryWriter(log_dir=f\"data_file/cv{fold}_{name}\")\n",
    "    for epoch in range(epochs) :\n",
    "        \n",
    "        # -- Train start\n",
    "        with tqdm(train_loader, total=train_loader.__len__(), unit='batch') as train_depth :\n",
    "            train_f1 = []\n",
    "            train_loss = []\n",
    "            for file_ in train_depth :\n",
    "                train_depth.set_description(f'Epoch {epoch+1} / {epochs}')\n",
    "                images = file_['image'].float().to(device)\n",
    "                labels = file_['label'].long().to(device)\n",
    "                \n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                pred = model(images)\n",
    "                loss = criterion(pred, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # print f1 score and loss\n",
    "                train_f1.append(f1_score(labels.cpu().detach().float(), torch.argmax(pred.cpu().detach(), 1), average='macro'))\n",
    "                train_loss.append(loss.item())\n",
    "                train_depth.set_postfix(f1=np.mean(train_f1), loss=np.mean(train_loss), Train=epoch+1)\n",
    "        \n",
    "        \n",
    "        # --  Validation start\n",
    "        with tqdm(valid_loader, total=valid_loader.__len__(), unit='batch') as valid_depth :\n",
    "            \n",
    "            valid_f1 = []\n",
    "            valid_loss = []\n",
    "            for file_ in valid_depth :\n",
    "                valid_depth.set_description(f'Epoch {epoch+1} / {epochs}')\n",
    "                imgs = file_['image'].float().to(device)\n",
    "                labels = file_['label'].long().to(device)\n",
    "                \n",
    "                model.eval()\n",
    "                optimizer.zero_grad()\n",
    "                with torch.no_grad() : \n",
    "                    pred = model(imgs)\n",
    "                    loss = criterion(pred, labels)\n",
    "\n",
    "                # print f1 score and loss\n",
    "                valid_f1.append(f1_score(labels.cpu().detach().float(), torch.argmax(pred.cpu().detach(), 1), average='macro'))\n",
    "                valid_loss.append(loss.item())\n",
    "                valid_depth.set_postfix(f1=np.mean(valid_f1), loss=np.mean(valid_loss), Valid=epoch+1)\n",
    "        \n",
    "        # 조기종료 조건 : 학습에서 Loss가 5번 이상 줄지 않으면 조기종료, 그렇지 않으면 저장\n",
    "        if np.mean(valid_loss) < min_loss :\n",
    "            min_loss = np.mean(valid_loss)\n",
    "            early_stop = 0\n",
    "            for f in glob(f'data_file/{name}/{fold}fold_*{name}.ckpt') :\n",
    "                open(f, 'w').close()\n",
    "                os.remove(f)\n",
    "            torch.save(model.state_dict(), f'data_file/{name}/{fold}fold_{epoch+1}epoch_{np.mean(valid_loss):2.4f}_{name}.ckpt')\n",
    "        else :\n",
    "            early_stop += 1\n",
    "            if early_stop >= 5 : break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9136db78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "# test는 validation과 동일한 구조를 가지게 진행하고 불러오는 이미지만 변경\n",
    "test_dir = '/opt/ml/input/data/eval'\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "test_image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "test_dataset = MaskDataset(test_image_paths, valid_transform, train_TF = False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "all_predictions = []\n",
    "for best_model in glob(f'data_file/{name}/*{name}.ckpt') :\n",
    "    \n",
    "    model = MyModel()\n",
    "    model.load_state_dict(torch.load(best_model))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    prediction_array=[]\n",
    "    \n",
    "    with tqdm(test_loader, total=test_loader.__len__(), unit='batch') as test_depth :\n",
    "        \n",
    "        for file_ in test_depth :\n",
    "            imgs = file_['image'].float().to(device)\n",
    "            pred = model(imgs)\n",
    "            pred = pred.cpu().detach().numpy()\n",
    "            prediction_array.extend(pred)\n",
    "    \n",
    "    all_predictions.append(np.array(prediction_array)[...,np.newaxis])\n",
    "submission['ans'] = np.argmax(np.mean(np.concatenate(all_predictions, axis=2), axis=2), axis=1)\n",
    "\n",
    "submission.to_csv(f'data_file/{name}/{name}.csv', index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b88980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
