{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92928b08",
   "metadata": {
    "id": "typical-cowboy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed : 37\n",
      "device : cuda:0\n",
      "_CudaDeviceProperties(name='Tesla V100-PCIE-32GB', major=7, minor=0, total_memory=32510MB, multi_processor_count=80)\n",
      "root : /opt/ml\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import PIL\n",
    "import os\n",
    "from glob import glob\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from adamp import AdamP\n",
    "from tqdm import tqdm, notebook\n",
    "from PIL import Image\n",
    "\n",
    "# random seed\n",
    "seed = 37\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(f'seed : {seed}')\n",
    "\n",
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device : {device}')\n",
    "print(torch.cuda.get_device_properties(device))\n",
    "\n",
    "# root\n",
    "root = os.getcwd()\n",
    "print(f'root : {root}')\n",
    "\n",
    "# Training Name\n",
    "name = 'B4dropout0.5.0830'\n",
    "if not os.path.isdir(f'data_file/{name}') :\n",
    "    os.chdir(os.path.join(root, 'data_file'))\n",
    "    os.mkdir(f'{name}')\n",
    "    os.chdir(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45c4c4c1",
   "metadata": {
    "id": "genetic-documentary"
   },
   "outputs": [],
   "source": [
    "path = Path('input/data/train/images')\n",
    "image_dirs = [str(x) for x in list(path.glob('*')) if '._' not in str(x)]\n",
    "# 'input/data/train/images/003277_female_Asian_19' 이런 형태 나옴\n",
    "\n",
    "image_dirs = np.array(image_dirs)\n",
    "\n",
    "# 나이와 성별 구분이 문제니까 이 두 개를 기준으로 나눠서 stratified_kfold하면 inbalance를 조금 방지할 수 있지 않을까?\n",
    "# 나이 성별 정보면 이용해서 데이터 나누기\n",
    "def label_fold(image_dirs):\n",
    "    stratified_kfold_label1 = []\n",
    "    for image_dir in image_dirs :\n",
    "        code = 0\n",
    "        if 'female' in image_dir : code += 3\n",
    "        else : code += 0 \n",
    "        \n",
    "        age = int(image_dir.split('/')[4][-2:])\n",
    "        if age >= 59 : code += 2\n",
    "        elif 30 <= age < 58 : code += 1\n",
    "        else : code += 0\n",
    "        stratified_kfold_label1.append(code)\n",
    "    label1 = np.array(stratified_kfold_label1)\n",
    "    return stratified_kfold_label1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "515fb1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음부터 kfold로 나눠서 할 수 있다. 데이터의 분포가 다른 경우\n",
    "def stratifiedkfold(image_dirs, label1):\n",
    "    stratified_kfold = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "    # Stratified K-Fold는 층화된 folds를 반환하는 기존 K-Fold의 변형된 방식. 각 집합에는 전체 집합과 거의 동일하게 클래스의 표본 비율이 포함된다. 불균형 클래스의 경우 사\n",
    "    # train에 2700개 중에서 4/5가 들어가고 valid에 1/5가 들어간다. 이걸 train할 때 다섯번 반복하면 된다.\n",
    "    fold_list = []\n",
    "    for train_data, valid_data in stratified_kfold.split(image_dirs, label1) : # split(x,y) x training data, y target\n",
    "        fold_list.append({'train':train_data, 'valid':valid_data})\n",
    "    return fold_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00f88e0f",
   "metadata": {
    "id": "editorial-denial"
   },
   "outputs": [],
   "source": [
    "# 'Mask까지 포함해서, 다시 labeling하기'\n",
    "def label_func(image_path) :\n",
    "    code = 0\n",
    "    if 'normal' in image_path : code += 12\n",
    "    elif 'incorrect_mask' in image_path : code += 6\n",
    "    else : code += 0\n",
    "\n",
    "    if 'female' in image_path : code += 3\n",
    "    else : code += 0\n",
    "\n",
    "    age = int(image_path.split('_')[3][:2])\n",
    "    if age >= 58 : code += 2\n",
    "    elif age < 58 : code += 1\n",
    "    else : code += 0\n",
    "    \n",
    "    return code\n",
    "\n",
    "class MaskDataset(Dataset) :\n",
    "    # path input/data/train/images/003277_female_Asian_19/mask3.jpg 이런 식으로 들어옴\n",
    "    def __init__(self, image_paths, transform, augment = None, training = False):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "        self.training = training\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = np.array(Image.open(self.image_paths[idx]))\n",
    "        \n",
    "        if self.augment: # augmentation 안하는 경우에\n",
    "            image = self.transform(self.augment(image = image)['image'])\n",
    "        else:    \n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.training : # 트레이닝 하는 경우에\n",
    "            label = label_func(self.image_paths[idx])\n",
    "            return {'image' : image, 'label' : label}\n",
    "            \n",
    "        else:\n",
    "            return {'image' : image}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5689f367",
   "metadata": {
    "id": "reflected-reputation"
   },
   "outputs": [],
   "source": [
    "# model\n",
    "# from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "class MyModel(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.model_name = EfficientNet.from_pretrained('efficientnet-b4', \n",
    "                                                in_channels=3, \n",
    "                                                num_classes=18) # weight가져오고 num_classes(두번째 파라미터로 학습시키는 class 수)\n",
    "\n",
    "    def forward(self, x) :\n",
    "        x = F.relu(self.model_name(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b4f0a4",
   "metadata": {
    "id": "future-solomon"
   },
   "source": [
    "## Define Transform and Augs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59ada1ac",
   "metadata": {
    "id": "musical-iceland"
   },
   "outputs": [],
   "source": [
    "# Transform\n",
    "'''\n",
    "transforms.ToPILImage() - csv 파일로 데이터셋을 받을 경우, PIL image로 바꿔준다.\n",
    "transforms.CenterCrop(size) - 가운데 부분을 size 크기로 자른다.\n",
    "transforms.Grayscale(num_output_channels=1) - grayscale로 변환한다.\n",
    "transforms.RandomAffine(degrees) - 랜덤으로 affine 변형을 한다.\n",
    "transforms.RandomCrop(size) -이미지를 랜덤으로 아무데나 잘라 size 크기로 출력한다.\n",
    "transforms.RandomResizedCrop(size) - 이미지 사이즈를 size로 변경한다\n",
    "transforms.Resize(size) - 이미지 사이즈를 size로 변경한다\n",
    "transforms.RandomRotation(degrees) 이미지를 랜덤으로 degrees 각도로 회전한다.\n",
    "transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333)) - 이미지를 랜덤으로 변형한다.\n",
    "transforms.RandomVerticalFlip(p=0.5) - 이미지를 랜덤으로 수직으로 뒤집는다. p =0이면 뒤집지 않는다.\n",
    "transforms.RandomHorizontalFlip(p=0.5) - 이미지를 랜덤으로 수평으로 뒤집는다.\n",
    "transforms.ToTensor() - 이미지 데이터를 tensor로 바꿔준다.\n",
    "transforms.Normalize(mean, std, inplace=False) - 이미지를 정규화한다.\n",
    "'''\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.CenterCrop([300,250]),\n",
    "    T.RandomHorizontalFlip(0.5),\n",
    "    T.RandomRotation(10),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246))\n",
    "])\n",
    "\n",
    "valid_transform = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.CenterCrop([300,250]),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a847b0dc",
   "metadata": {
    "id": "perceived-muscle"
   },
   "outputs": [],
   "source": [
    "# Hyper-params\n",
    "'Batch Size는 Center Crop의 크기에 따라 변경될 수 있습니다.'\n",
    "batch_size = 32\n",
    "lr = 1e-4\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d6a6e45a",
   "metadata": {
    "id": "adjustable-newport",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_fold number 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/473 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.37batch/s, Train=1, f1=0.266, loss=1.96]\n",
      "Epoch 1 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.91batch/s, Valid=1, f1=0.772, loss=0.984]\n",
      "Epoch 2 / 10: 100%|██████████| 473/473 [03:18<00:00,  2.38batch/s, Train=2, f1=0.356, loss=1.68]\n",
      "Epoch 2 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.91batch/s, Valid=2, f1=0.766, loss=0.825]\n",
      "Epoch 3 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.38batch/s, Train=3, f1=0.399, loss=1.6]\n",
      "Epoch 3 / 10: 100%|██████████| 473/473 [00:17<00:00, 27.03batch/s, Valid=3, f1=0.765, loss=0.73]\n",
      "Epoch 4 / 10: 100%|██████████| 473/473 [03:18<00:00,  2.38batch/s, Train=4, f1=0.411, loss=1.55]\n",
      "Epoch 4 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.92batch/s, Valid=4, f1=0.768, loss=0.7]\n",
      "Epoch 5 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.37batch/s, Train=5, f1=0.435, loss=1.53]\n",
      "Epoch 5 / 10: 100%|██████████| 473/473 [00:17<00:00, 27.00batch/s, Valid=5, f1=0.743, loss=0.722]\n",
      "Epoch 6 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.37batch/s, Train=6, f1=0.448, loss=1.5]\n",
      "Epoch 6 / 10: 100%|██████████| 473/473 [00:18<00:00, 26.20batch/s, Valid=6, f1=0.762, loss=0.699]\n",
      "Epoch 7 / 10: 100%|██████████| 473/473 [03:20<00:00,  2.36batch/s, Train=7, f1=0.469, loss=1.47]\n",
      "Epoch 7 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.36batch/s, Valid=7, f1=0.766, loss=0.653]\n",
      "Epoch 8 / 10: 100%|██████████| 473/473 [03:20<00:00,  2.36batch/s, Train=8, f1=0.468, loss=1.48]\n",
      "Epoch 8 / 10: 100%|██████████| 473/473 [00:18<00:00, 26.13batch/s, Valid=8, f1=0.76, loss=0.695]\n",
      "Epoch 9 / 10: 100%|██████████| 473/473 [03:20<00:00,  2.36batch/s, Train=9, f1=0.472, loss=1.49]\n",
      "Epoch 9 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.65batch/s, Valid=9, f1=0.768, loss=0.688]\n",
      "Epoch 10 / 10: 100%|██████████| 473/473 [03:20<00:00,  2.36batch/s, Train=10, f1=0.469, loss=1.49]\n",
      "Epoch 10 / 10: 100%|██████████| 473/473 [00:18<00:00, 26.17batch/s, Valid=10, f1=0.757, loss=0.737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_fold number 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/473 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10: 100%|██████████| 473/473 [03:20<00:00,  2.36batch/s, Train=1, f1=0.273, loss=1.93]\n",
      "Epoch 1 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.96batch/s, Valid=1, f1=0.751, loss=0.954]\n",
      "Epoch 2 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.37batch/s, Train=2, f1=0.355, loss=1.68]\n",
      "Epoch 2 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.75batch/s, Valid=2, f1=0.766, loss=0.832]\n",
      "Epoch 3 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.37batch/s, Train=3, f1=0.392, loss=1.59]\n",
      "Epoch 3 / 10: 100%|██████████| 473/473 [00:17<00:00, 27.11batch/s, Valid=3, f1=0.742, loss=0.824]\n",
      "Epoch 4 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.37batch/s, Train=4, f1=0.416, loss=1.54]\n",
      "Epoch 4 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.83batch/s, Valid=4, f1=0.783, loss=0.72]\n",
      "Epoch 5 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.37batch/s, Train=5, f1=0.438, loss=1.53]\n",
      "Epoch 5 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.65batch/s, Valid=5, f1=0.778, loss=0.68]\n",
      "Epoch 6 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.38batch/s, Train=6, f1=0.455, loss=1.51]\n",
      "Epoch 6 / 10: 100%|██████████| 473/473 [00:17<00:00, 27.14batch/s, Valid=6, f1=0.764, loss=0.699]\n",
      "Epoch 7 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.38batch/s, Train=7, f1=0.453, loss=1.51]\n",
      "Epoch 7 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.86batch/s, Valid=7, f1=0.753, loss=0.731]\n",
      "Epoch 8 / 10: 100%|██████████| 473/473 [03:20<00:00,  2.36batch/s, Train=8, f1=0.463, loss=1.48]\n",
      "Epoch 8 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.96batch/s, Valid=8, f1=0.792, loss=0.625]\n",
      "Epoch 9 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.37batch/s, Train=9, f1=0.469, loss=1.48]\n",
      "Epoch 9 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.55batch/s, Valid=9, f1=0.77, loss=0.654]\n",
      "Epoch 10 / 10: 100%|██████████| 473/473 [03:20<00:00,  2.36batch/s, Train=10, f1=0.474, loss=1.49]\n",
      "Epoch 10 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.52batch/s, Valid=10, f1=0.777, loss=0.671]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_fold number 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/473 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10: 100%|██████████| 473/473 [03:20<00:00,  2.36batch/s, Train=1, f1=0.261, loss=1.95]\n",
      "Epoch 1 / 10: 100%|██████████| 473/473 [00:17<00:00, 27.07batch/s, Valid=1, f1=0.765, loss=0.921]\n",
      "Epoch 2 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.37batch/s, Train=2, f1=0.357, loss=1.66]\n",
      "Epoch 2 / 10: 100%|██████████| 473/473 [00:17<00:00, 27.01batch/s, Valid=2, f1=0.765, loss=0.805]\n",
      "Epoch 3 / 10: 100%|██████████| 473/473 [03:18<00:00,  2.38batch/s, Train=3, f1=0.389, loss=1.59]\n",
      "Epoch 3 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.87batch/s, Valid=3, f1=0.784, loss=0.758]\n",
      "Epoch 4 / 10: 100%|██████████| 473/473 [03:20<00:00,  2.36batch/s, Train=4, f1=0.418, loss=1.54]\n",
      "Epoch 4 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.99batch/s, Valid=4, f1=0.783, loss=0.748]\n",
      "Epoch 5 / 10: 100%|██████████| 473/473 [03:20<00:00,  2.35batch/s, Train=5, f1=0.433, loss=1.52]\n",
      "Epoch 5 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.86batch/s, Valid=5, f1=0.772, loss=0.672]\n",
      "Epoch 6 / 10: 100%|██████████| 473/473 [03:20<00:00,  2.36batch/s, Train=6, f1=0.45, loss=1.49]\n",
      "Epoch 6 / 10: 100%|██████████| 473/473 [00:17<00:00, 27.06batch/s, Valid=6, f1=0.767, loss=0.693]\n",
      "Epoch 7 / 10: 100%|██████████| 473/473 [03:20<00:00,  2.36batch/s, Train=7, f1=0.454, loss=1.51]\n",
      "Epoch 7 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.45batch/s, Valid=7, f1=0.79, loss=0.695]\n",
      "Epoch 8 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.37batch/s, Train=8, f1=0.47, loss=1.48]\n",
      "Epoch 8 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.64batch/s, Valid=8, f1=0.787, loss=0.669]\n",
      "Epoch 9 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.37batch/s, Train=9, f1=0.472, loss=1.48]\n",
      "Epoch 9 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.71batch/s, Valid=9, f1=0.757, loss=0.719]\n",
      "Epoch 10 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.37batch/s, Train=10, f1=0.476, loss=1.48]\n",
      "Epoch 10 / 10: 100%|██████████| 473/473 [00:17<00:00, 27.09batch/s, Valid=10, f1=0.779, loss=0.696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_fold number 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/473 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.37batch/s, Train=1, f1=0.272, loss=1.94]\n",
      "Epoch 1 / 10: 100%|██████████| 473/473 [00:17<00:00, 27.10batch/s, Valid=1, f1=0.737, loss=1.02]\n",
      "Epoch 2 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.37batch/s, Train=2, f1=0.354, loss=1.68]\n",
      "Epoch 2 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.72batch/s, Valid=2, f1=0.748, loss=0.868]\n",
      "Epoch 3 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.37batch/s, Train=3, f1=0.386, loss=1.61]\n",
      "Epoch 3 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.97batch/s, Valid=3, f1=0.736, loss=0.79]\n",
      "Epoch 4 / 10: 100%|██████████| 473/473 [03:21<00:00,  2.35batch/s, Train=4, f1=0.405, loss=1.57]\n",
      "Epoch 4 / 10: 100%|██████████| 473/473 [00:17<00:00, 27.12batch/s, Valid=4, f1=0.732, loss=0.8]\n",
      "Epoch 5 / 10: 100%|██████████| 473/473 [03:20<00:00,  2.36batch/s, Train=5, f1=0.424, loss=1.53]\n",
      "Epoch 5 / 10: 100%|██████████| 473/473 [00:17<00:00, 27.07batch/s, Valid=5, f1=0.741, loss=0.785]\n",
      "Epoch 6 / 10: 100%|██████████| 473/473 [03:20<00:00,  2.36batch/s, Train=6, f1=0.444, loss=1.5]\n",
      "Epoch 6 / 10: 100%|██████████| 473/473 [00:17<00:00, 27.16batch/s, Valid=6, f1=0.725, loss=0.767]\n",
      "Epoch 7 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.37batch/s, Train=7, f1=0.453, loss=1.49]\n",
      "Epoch 7 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.94batch/s, Valid=7, f1=0.738, loss=0.737]\n",
      "Epoch 8 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.37batch/s, Train=8, f1=0.466, loss=1.47]\n",
      "Epoch 8 / 10: 100%|██████████| 473/473 [00:17<00:00, 27.29batch/s, Valid=8, f1=0.742, loss=0.755]\n",
      "Epoch 9 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.37batch/s, Train=9, f1=0.455, loss=1.51]\n",
      "Epoch 9 / 10: 100%|██████████| 473/473 [00:17<00:00, 27.13batch/s, Valid=9, f1=0.746, loss=0.803]\n",
      "Epoch 10 / 10: 100%|██████████| 473/473 [03:20<00:00,  2.36batch/s, Train=10, f1=0.477, loss=1.47]\n",
      "Epoch 10 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.85batch/s, Valid=10, f1=0.74, loss=0.793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_fold number 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/473 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.37batch/s, Train=1, f1=0.274, loss=1.93]\n",
      "Epoch 1 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.35batch/s, Valid=1, f1=0.747, loss=1.01]\n",
      "Epoch 2 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.37batch/s, Train=2, f1=0.36, loss=1.66]\n",
      "Epoch 2 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.89batch/s, Valid=2, f1=0.736, loss=0.924]\n",
      "Epoch 3 / 10: 100%|██████████| 473/473 [03:20<00:00,  2.36batch/s, Train=3, f1=0.385, loss=1.6]\n",
      "Epoch 3 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.89batch/s, Valid=3, f1=0.757, loss=0.734]\n",
      "Epoch 4 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.37batch/s, Train=4, f1=0.42, loss=1.54]\n",
      "Epoch 4 / 10: 100%|██████████| 473/473 [00:17<00:00, 27.00batch/s, Valid=4, f1=0.756, loss=0.763]\n",
      "Epoch 5 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.38batch/s, Train=5, f1=0.425, loss=1.53]\n",
      "Epoch 5 / 10: 100%|██████████| 473/473 [00:17<00:00, 27.00batch/s, Valid=5, f1=0.761, loss=0.729]\n",
      "Epoch 6 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.37batch/s, Train=6, f1=0.451, loss=1.5]\n",
      "Epoch 6 / 10: 100%|██████████| 473/473 [00:17<00:00, 27.51batch/s, Valid=6, f1=0.765, loss=0.743]\n",
      "Epoch 7 / 10: 100%|██████████| 473/473 [03:19<00:00,  2.38batch/s, Train=7, f1=0.457, loss=1.48]\n",
      "Epoch 7 / 10: 100%|██████████| 473/473 [00:17<00:00, 27.43batch/s, Valid=7, f1=0.734, loss=0.781]\n",
      "Epoch 8 / 10: 100%|██████████| 473/473 [03:18<00:00,  2.38batch/s, Train=8, f1=0.464, loss=1.49]\n",
      "Epoch 8 / 10: 100%|██████████| 473/473 [00:17<00:00, 27.01batch/s, Valid=8, f1=0.749, loss=0.729]\n",
      "Epoch 9 / 10: 100%|██████████| 473/473 [03:18<00:00,  2.38batch/s, Train=9, f1=0.465, loss=1.51]\n",
      "Epoch 9 / 10: 100%|██████████| 473/473 [00:17<00:00, 26.65batch/s, Valid=9, f1=0.761, loss=0.736]\n",
      "Epoch 10 / 10: 100%|██████████| 473/473 [03:20<00:00,  2.36batch/s, Train=10, f1=0.477, loss=1.47]\n",
      "Epoch 10 / 10: 100%|██████████| 473/473 [00:17<00:00, 27.12batch/s, Valid=10, f1=0.741, loss=0.752]\n"
     ]
    }
   ],
   "source": [
    "# -- Training\n",
    "# kfold로 데이터 나누기\n",
    "label1 = label_fold(image_dirs)\n",
    "fold_list = stratifiedkfold(image_dirs, label1)\n",
    "k_fold = [1, 2, 3, 4, 5] # 총 5개\n",
    "\n",
    "for fold in k_fold :\n",
    "    print(f'k_fold number {fold}')\n",
    "    min_loss = 5\n",
    "    early_stop = 0\n",
    "    \n",
    "    # -- dataset 만들기 위한 경로 리스트 만들기\n",
    "    train_image_paths = []\n",
    "    for train_dir in image_dirs[fold_list[fold-1]['train']] :\n",
    "        train_image_paths.extend(glob(train_dir+'/*'))\n",
    "    \n",
    "    valid_image_paths = []\n",
    "    for valid_dir in image_dirs[fold_list[fold-1]['valid']] :\n",
    "        valid_image_paths.extend(glob(valid_dir+'/*'))\n",
    "    \n",
    "    # -- dataset\n",
    "    train_dataset = MaskDataset(train_image_paths, train_transform, training=True)\n",
    "    valid_dataset = MaskDataset(valid_image_paths, valid_transform, training=True)\n",
    "    \n",
    "    # -- data_loader\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "    valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size//4, shuffle=True, num_workers=3)\n",
    "    \n",
    "    # -- model\n",
    "    model = MyModel()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # -- loss & metric\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = AdamP(model.parameters(), lr=lr)\n",
    "\n",
    "    # -- epoch\n",
    "    for epoch in range(epochs) :\n",
    "        \n",
    "        # -- Train start\n",
    "        with tqdm(train_loader, total=train_loader.__len__(), unit='batch') as train_depth :\n",
    "            train_f1_score = []\n",
    "            train_loss = []\n",
    "            for sample in train_depth:\n",
    "                train_depth.set_description(f'Epoch {epoch+1} / {epochs}')\n",
    "                images = sample['image'].float().to(device)\n",
    "                labels = sample['label'].long().to(device)\n",
    "\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                pred = model(images)\n",
    "                loss = loss_func(pred, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # print f1 score and loss\n",
    "                train_f1_score.append(f1_score(labels.cpu().detach().float(), torch.argmax(pred.cpu().detach(), 1), average='macro'))\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "                train_depth.set_postfix(f1=np.mean(train_f1_score), loss=np.mean(train_loss), Train=epoch+1)\n",
    "        \n",
    "        # -- Validation start\n",
    "        with tqdm(valid_loader, total=valid_loader.__len__(), unit='batch') as valid_depth :\n",
    "            valid_f1_score = []\n",
    "            valid_loss = []\n",
    "            for sample in valid_depth :\n",
    "                valid_depth.set_description(f'Epoch {epoch+1} / {epochs}')\n",
    "                imgs = sample['image'].float().to(device)\n",
    "                labels = sample['label'].long().to(device)\n",
    "                \n",
    "                model.eval()\n",
    "                optimizer.zero_grad()\n",
    "                with torch.no_grad() : \n",
    "                    pred = model(imgs)\n",
    "                    loss = loss_func(pred, labels)\n",
    "\n",
    "                # postfix로 출력\n",
    "                valid_f1_score.append(f1_score(labels.cpu().detach().float(), torch.argmax(pred.cpu().detach(), 1), average='macro'))\n",
    "                valid_loss.append(loss.item())\n",
    "                valid_depth.set_postfix(f1=np.mean(valid_f1_score), loss=np.mean(valid_loss), Valid=epoch+1)\n",
    "        \n",
    "        # Loss가 낮아질 때, 해당 Model을 저장\n",
    "        if np.mean(valid_loss) < min_loss :\n",
    "            min_loss = np.mean(valid_loss) # 갱신\n",
    "            early_stop = 0\n",
    "            for f in glob(f'data_file/{name}/{fold}fold_*{name}.pt') :\n",
    "                open(f, 'w').close()\n",
    "                os.remove(f)\n",
    "            torch.save(model.state_dict(), f'data_file/{name}/{fold}fold_{epoch+1}epoch_{np.mean(valid_loss):2.4f}_{name}.pt')\n",
    "        # loss가 다섯 번 이상 좋아지지 않으면 조기종료\n",
    "        else :\n",
    "            early_stop += 1\n",
    "        if early_stop >= 5 :\n",
    "            print('Early Stop')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f091ac1",
   "metadata": {
    "id": "outstanding-leader"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 394/394 [01:27<00:00,  4.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 394/394 [01:26<00:00,  4.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 394/394 [01:26<00:00,  4.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 394/394 [01:27<00:00,  4.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 394/394 [01:27<00:00,  4.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "\n",
    "submission = pd.read_csv('input/data/eval/info.csv')\n",
    "test_image_paths = [os.path.join('input/data/eval/images', image_file) for image_file in submission.ImageID]\n",
    "\n",
    "# Test Dataset, DataLoader를 만들기\n",
    "test_dataset = MaskDataset(test_image_paths, valid_transform, training=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "prediction_lst = []\n",
    "for best_model in glob(f'data_file/{name}/*{name}.pt') :\n",
    "    model = MyModel()\n",
    "    model.load_state_dict(torch.load(best_model))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    prediction_list=[]\n",
    "    \n",
    "    with tqdm(test_loader, total=test_loader.__len__(), unit='batch') as test_depth :\n",
    "        for sample in test_depth :\n",
    "            images = sample['image'].float().to(device)\n",
    "            pred = model(images)\n",
    "            pred = pred.cpu().detach().numpy()\n",
    "            prediction_list.extend(pred)\n",
    "    \n",
    "    prediction_lst.append(np.array(prediction_list)[...,np.newaxis])\n",
    "\n",
    "submission['ans'] = np.argmax(np.mean(np.concatenate(prediction_lst, axis=2), axis=2), axis=1)\n",
    "submission.to_csv(f'data_file/{name}/{name}.csv', index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b10dd9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12600"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83414aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cea562",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Code.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
