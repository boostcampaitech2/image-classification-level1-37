{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16afe1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed : 37\n",
      "device : cuda:0\n",
      "_CudaDeviceProperties(name='Tesla V100-PCIE-32GB', major=7, minor=0, total_memory=32510MB, multi_processor_count=80)\n",
      " current working direcory : /opt/ml\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from adamp import AdamP\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm, notebook\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# random seed\n",
    "seed = 37\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(f'seed : {seed}')\n",
    "\n",
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device : {device}')\n",
    "print(torch.cuda.get_device_properties(device))\n",
    "\n",
    "# current working directory\n",
    "cwd = os.getcwd()\n",
    "print(f' current working direcory : {cwd}')\n",
    "\n",
    "# Training data will be stored in this folder\n",
    "name = 'restoration_final_dropout' # 경로 이름 지정\n",
    "if not os.path.isdir(f'data_file/{name}') :\n",
    "    os.chdir(os.path.join(cwd, 'data_file'))\n",
    "    os.mkdir(f'{name}')\n",
    "    os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cde79206",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('input/data/train/images')\n",
    "image_dirs = [str(x) for x in list(path.glob('*')) if '._' not in str(x)]\n",
    "# 'input/data/train/images/003277_female_Asian_19' 이런 형태가 나온다.\n",
    "# np.array 형식으로 변환\n",
    "image_dirs = np.array(image_dirs)\n",
    "\n",
    "# 나이와 성별 구분이 문제니까 이 두 개를 기준으로 나눠서 stratified_kfold를 사용하면 imbalance를 조금 방지할 수 있지 않을까?\n",
    "# 나이 성별 정보면 이용해서 데이터 나누기\n",
    "# 나이가 60세 이상 정보가 너무 부족하니까 학습시에 나이 58을 기준으로 나눠서 진행\n",
    "# 18개의 class를 따로 나눠서 데이터 셋을 나누는 것 보다 교집합이 있는 부분끼리 \n",
    "\n",
    "def label_fold(image_dirs):\n",
    "    stratified_kfold_label = []\n",
    "    for image_dir in image_dirs :\n",
    "        cnt = 0\n",
    "        if 'female' in image_dir : cnt += 3\n",
    "        else : cnt += 0 \n",
    "        \n",
    "        age = int(image_dir.split('_')[3][:2])\n",
    "        if age < 30 : cnt += 0\n",
    "        elif age < 58 : cnt += 1\n",
    "        else : cnt += 2\n",
    "        stratified_kfold_label.append(cnt)\n",
    "    stratified_kfold_label = np.array(stratified_kfold_label)\n",
    "    stratified_kfold = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "    \n",
    "    # Stratified K-Fold는 층화된 folds를 반환하는 기존 K-Fold의 변형된 방식이다. 각 집합에는 전체 집합과 거의 동일하게 클래스의 표본 비율이 포함된다. \n",
    "    # 불균형 클래스의 경우 사용을 많이 한다. 이를 통해 데이터별로 가지는 클래스의 분포를 맞춰줄 수 있을 것으로 기대한다.\n",
    "    # train에 2700개의 id 중에서 4/5가 들어가고 valid에 1/5가 들어간다. 이걸 다른 모양으로 train할 때 다섯번 반복하게 된다.\n",
    "    fold_list = []\n",
    "    for train_data, valid_data in stratified_kfold.split(image_dirs, stratified_kfold_label) :\n",
    "        fold_list.append({'train':train_data, 'valid':valid_data})\n",
    "    return fold_list\n",
    "\n",
    "fold_list = label_fold(image_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbac6573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Mask까지 포함해서, 다시 라벨링해서 원래 데이터 class로 맞춰준다.\n",
    "def label_func(image_paths) :\n",
    "        cnt = 0\n",
    "        if 'normal' in image_paths : cnt += 12\n",
    "        elif 'incorrect_mask' in image_paths : cnt += 6\n",
    "        else : cnt += 0\n",
    "\n",
    "        if 'female' in image_paths : cnt += 3\n",
    "        else : cnt += 0\n",
    "\n",
    "        age = int(image_paths.split('_')[3][:2])\n",
    "        if age < 30 : cnt += 0\n",
    "        elif age < 58 : cnt += 1\n",
    "        else : cnt += 2\n",
    "\n",
    "        return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "458581b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class MaskDataset(Dataset) :\n",
    "    # image_paths는 path input/data/train/images/003277_female_Asian_19/mask3.jpg 이런 식으로 들어온다.\n",
    "    def __init__(self, image_paths, transform, augment = None, train_TF = False):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "        self.train_TF = train_TF\n",
    "        \n",
    "    def __len__(self) :\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = np.array(Image.open(self.image_paths[idx]))\n",
    "        \n",
    "        if self.augment: # augmentation하는 경우에\n",
    "            image = self.transform(self.augment(image = image)['image'])\n",
    "        else:    \n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.train_TF : # 트레이닝하는 경우\n",
    "            label = label_func(self.image_paths[idx])\n",
    "            return {'image' : image, 'label' : label}\n",
    "            \n",
    "        else:\n",
    "            return {'image' : image}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc884bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform\n",
    "'''\n",
    "transforms.ToPILImage() - csv 파일로 데이터셋을 받을 경우, PIL image로 바꿔준다.\n",
    "transforms.CenterCrop(size) - 가운데 부분을 size 크기로 자른다.\n",
    "transforms.Grayscale(num_output_channels=1) - grayscale로 변환한다.\n",
    "transforms.RandomAffine(degrees) - 랜덤으로 affine 변형을 한다.\n",
    "transforms.RandomCrop(size) -이미지를 랜덤으로 아무데나 잘라 size 크기로 출력한다.\n",
    "transforms.RandomResizedCrop(size) - 이미지 사이즈를 size로 변경한다\n",
    "transforms.Resize(size) - 이미지 사이즈를 size로 변경한다\n",
    "transforms.RandomRotation(degrees) 이미지를 랜덤으로 degrees 각도로 회전한다.\n",
    "transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333)) - 이미지를 랜덤으로 변형한다.\n",
    "transforms.RandomVerticalFlip(p=0.5) - 이미지를 랜덤으로 수직으로 뒤집는다. p =0이면 뒤집지 않는다.\n",
    "transforms.RandomHorizontalFlip(p=0.5) - 이미지를 랜덤으로 수평으로 뒤집는다.\n",
    "transforms.ToTensor() - 이미지 데이터를 tensor로 바꿔준다.\n",
    "transforms.Normalize(mean, std, inplace=False) - 이미지를 정규화한다.\n",
    "'''\n",
    "# centercrop을 통해 얼굴에서 벗어나는 부분을 줄여준다. \n",
    "# 멘토님이 중요하게 augmentation해야 한다한 부분 중, rotation, flip이 이미지 데이터 생긴 형태와 가장 잘 맞는다고 판단해서 이 두개로 진행\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.CenterCrop([300,250]),\n",
    "    T.RandomRotation(10),\n",
    "    T.RandomHorizontalFlip(0.5),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246))\n",
    "])\n",
    "\n",
    "# valid_transform에서는 기본적인 것만 가져가고 augmentation한 것을 빼고 검증을 거친다.\n",
    "valid_transform = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.CenterCrop([300,250]),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.56, 0.51, 0.48), std=(0.22, 0.24, 0.25))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1812210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "# -- model\n",
    "# 왜 relu를 이걸 만들 때 넣었는지 모르겠지만 생각보다 잘 동작하긴 했다.\n",
    "# efficientnet 중에서 파라미터 수가 적당하고 성능도 괜찮은 b3, b4로 테스트를 진행했다.\n",
    "class Myeff4Model(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.model_name = EfficientNet.from_pretrained('efficientnet-b4', \n",
    "                                                in_channels=3, \n",
    "                                                num_classes=18) # weight가져오고 num_classes(두번째 파라미터로 학습시키는 class 수)\n",
    "        self.model_name._dropout = nn.Dropout(p=0.7, inplace=False)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x = F.relu(self.model_name(x))\n",
    "        return x\n",
    "\n",
    "    \n",
    "class Myeff3Model(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.model_name = EfficientNet.from_pretrained('efficientnet-b3', \n",
    "                                                in_channels=3, \n",
    "                                                num_classes=18) # weight가져오고 num_classes(두번째 파라미터로 학습시키는 class 수)\n",
    "    def forward(self, x) :\n",
    "        x = F.relu(self.model_name(x))\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27dea0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "batch_size = 16\n",
    "lr = 1e-4\n",
    "epochs = 10\n",
    "\n",
    "counter = 0\n",
    "patience = 10\n",
    "accumulation_steps = 2\n",
    "best_val_acc = 0\n",
    "best_val_loss = np.inf\n",
    "lr_decay_step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cf42e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold number 1\n",
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/945 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6749221a1065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtrain_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfile_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_depth\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                 \u001b[0mtrain_depth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch+1} / {epochs}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training and Validating\n",
    "\n",
    "folds_index = [1, 2, 3, 4, 5] # 총 5개\n",
    "\n",
    "for fold in folds_index :\n",
    "    print(f'Fold number {fold}')\n",
    "    min_loss = 3\n",
    "    early_stop = 0\n",
    "\n",
    "# -- kfold를 이용해서 dataset을 만들기 위한 경로 리스트\n",
    "    train_image_paths, valid_image_paths = [], []\n",
    "\n",
    "    # -- train_data\n",
    "    for train_dir in image_dirs[fold_list[fold-1]['train']] :\n",
    "        train_image_paths.extend(glob(train_dir+'/*'))\n",
    "    train_dataset = MaskDataset(train_image_paths, train_transform, train_TF=True)\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "    \n",
    "    # -- valid_data\n",
    "    for valid_dir in image_dirs[fold_list[fold-1]['valid']] :\n",
    "        valid_image_paths.extend(glob(valid_dir+'/*'))\n",
    "    valid_dataset = MaskDataset(valid_image_paths, valid_transform, train_TF=True)\n",
    "    valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size//4, shuffle=True, num_workers=3)\n",
    "    \n",
    "    # -- model\n",
    "    model = Myeff3Model() # Myeff3Model, Myeff4Model\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # -- loss & metric\n",
    "    optimizer = AdamP(model.parameters(), lr=lr) # Adam or AdamP\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    scheduler = StepLR(optimizer, lr_decay_step, gamma=0.5)\n",
    "\n",
    "    # -- logging\n",
    "    logger = SummaryWriter(log_dir=f\"data_file/cv{fold}_{name}\")\n",
    "    for epoch in range(epochs) :\n",
    "        \n",
    "        # -- Train start\n",
    "        with tqdm(train_loader, total=train_loader.__len__(), unit='batch') as train_depth :\n",
    "            train_f1 = []\n",
    "            train_loss = []\n",
    "            for file_ in train_depth :\n",
    "                train_depth.set_description(f'Epoch {epoch+1} / {epochs}')\n",
    "                images = file_['image'].float().to(device)\n",
    "                labels = file_['label'].long().to(device)\n",
    "                \n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                pred = model(images)\n",
    "                loss = criterion(pred, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # print f1 score and loss\n",
    "                train_f1.append(f1_score(labels.cpu().detach().float(), torch.argmax(pred.cpu().detach(), 1), average='macro'))\n",
    "                train_loss.append(loss.item())\n",
    "                train_depth.set_postfix(f1=np.mean(train_f1), loss=np.mean(train_loss), Train=epoch+1)\n",
    "        \n",
    "        \n",
    "        # --  Validation start\n",
    "        with tqdm(valid_loader, total=valid_loader.__len__(), unit='batch') as valid_depth :\n",
    "            \n",
    "            valid_f1 = []\n",
    "            valid_loss = []\n",
    "            for file_ in valid_depth :\n",
    "                valid_depth.set_description(f'Epoch {epoch+1} / {epochs}')\n",
    "                imgs = file_['image'].float().to(device)\n",
    "                labels = file_['label'].long().to(device)\n",
    "                \n",
    "                model.eval()\n",
    "                optimizer.zero_grad()\n",
    "                with torch.no_grad() : \n",
    "                    pred = model(imgs)\n",
    "                    loss = criterion(pred, labels)\n",
    "\n",
    "                # print f1 score and loss\n",
    "                valid_f1.append(f1_score(labels.cpu().detach().float(), torch.argmax(pred.cpu().detach(), 1), average='macro'))\n",
    "                valid_loss.append(loss.item())\n",
    "                valid_depth.set_postfix(f1=np.mean(valid_f1), loss=np.mean(valid_loss), Valid=epoch+1)\n",
    "        \n",
    "        # 조기종료 조건 : 학습에서 Loss가 5번 이상 줄지 않으면 조기종료, 그렇지 않으면 저장\n",
    "        if np.mean(valid_loss) < min_loss :\n",
    "            min_loss = np.mean(valid_loss)\n",
    "            early_stop = 0\n",
    "            for f in glob(f'data_file/{name}/{fold}fold_*{name}.ckpt') :\n",
    "                open(f, 'w').close()\n",
    "                os.remove(f)\n",
    "            torch.save(model.state_dict(), f'data_file/{name}/{fold}fold_{epoch+1}epoch_{np.mean(valid_loss):2.4f}_{name}.ckpt')\n",
    "        else :\n",
    "            early_stop += 1\n",
    "            if early_stop >= 5 : break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8b2cfe-ef66-48d7-921f-86d4a1e21411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9136db78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "# test는 validation과 동일한 구조를 가지게 진행하고 불러오는 이미지만 변경\n",
    "test_dir = '/opt/ml/input/data/eval'\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "test_image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "test_dataset = MaskDataset(test_image_paths, valid_transform, train_TF = False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "all_predictions = []\n",
    "for best_model in glob(f'data_file/{name}/*{name}.ckpt') :\n",
    "    \n",
    "    model = MyModel()\n",
    "    model.load_state_dict(torch.load(best_model))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    prediction_array=[]\n",
    "    \n",
    "    with tqdm(test_loader, total=test_loader.__len__(), unit='batch') as test_depth :\n",
    "        \n",
    "        for file_ in test_depth :\n",
    "            imgs = file_['image'].float().to(device)\n",
    "            pred = model(imgs)\n",
    "            pred = pred.cpu().detach().numpy()\n",
    "            prediction_array.extend(pred)\n",
    "    \n",
    "    all_predictions.append(np.array(prediction_array)[...,np.newaxis])\n",
    "submission['ans'] = np.argmax(np.mean(np.concatenate(all_predictions, axis=2), axis=2), axis=1)\n",
    "\n",
    "submission.to_csv(f'data_file/{name}/{name}.csv', index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b88980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
